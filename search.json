[{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Replication analyses with eatRep","text":"following vignette demonstrates analyses based replication methods (Krewski & Rao, 1981; Rust, 2014; Rust & Rao, 1996; Wolter, 2007). Replication methods quite common context survey large-scale assessment data (Foy et al., 2008) like “National Assessment Studies IQB Trends Student Achievement” . following examples closely related “IQB” context (e.g., jackknife-2 methods used instead balanced repeated replicates), may adapted PISA TIMSS analyses well. illustration eatRep can applied PISA data specific replication design, see last example documentation repMean() function. Please note theoretical foundations presented methods beyond scope vignette—literature recommendations depth theoretical discussions can found package documentation (type package?eatRep console). Instead, vignette focuses prototypical analyses. Furthermore, note IRT item calibration “plausible values” imputation covered vignette. outlined analyses base survey data “plausible values” already included. kind data provided OECD can requested “Research Data Centre (FDZ) IQB”. analyses comprise descriptive statistics (means, standard deviations), frequency distributions, linear logistic regression models. Usually, sampling designs large-scale assessments following, specific characteristics: Often, individuals survey data randomly drawn population. educational assessments aim compare countries, example, proportions sample necessarily correspond proportions population. Often, institutions like OECD provide sampling weights according data allow estimate population parameters. (primary) sampling units educational data classes instead individuals. Hence, sample clustered. Students within class alike students different classes. Therefore, clustered sampled students homogeneous randomly sampled students may lead biased standard error estimates inference-based analyses. Variables interest (e.g. educational achievement) latent directly observable (inherently missing). Additionally, questionnaire data frequently include missing responses. Therefore, institutions like OECD IQB provide imputed data. eatRep allows compute (adjusted) means mean differences, frequency tables, percentiles, parameter (log) linear regression models, taking clustered /imputed sample account via replication methods. Trend analyses possible well. eatRep meets special features mentioned (apply) following way: 1.: include sampling weights analyses. 2.: Use replication methods (Bootstrap, jackknife “Balanced repeated replicates”) inference statistics. 3.: Pool results applying specific rules (Little & Rubin, 1987; Rubin, 2003). However, eatRep also suitable data clustered without imputations imputed without clustered sampling. three mentioned methods (using weights, replication methods, pooling methods) can called independently .","code":""},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"installation","dir":"Articles","previous_headings":"","what":"0. Installation","title":"Replication analyses with eatRep","text":"recommend use R version 4.0.0 higher. eatRep available CRAN:","code":"install.packages(\"eatRep\")"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"example-data","dir":"Articles","previous_headings":"","what":"1. Example data","title":"Replication analyses with eatRep","text":"eatRep contains exemplary data named lsa (“large scale assessment”), resembles “IQB Gesamtanalysedatensatz (GADS)”. lsa, however, reduced numbers examinees, imputations, variables. package loaded, structure lsa can inspected via: lsa long format; means data set contains multiple rows per individual person. Imputed variables (e.g., migration background, mig) occur several columns (mig_Imp_1, mig_Imp_2, mig_Imp_3, ), : mig. Multiple imputations stored multiple rows, variable imp yields number imputed data set. Furthermore, variables refer different competence domains (reading, listening) different imputations different times measurement (.e., competence variable score) occur multiple columns (reading_2010_score_Imp_1, reading_2010_score_Imp_2, …, listening_2010_score_Imp_1, listening_2015_score_Imp_1, …). score occurs , imp defines imputation, whereas domain gives competence domain. reshape data long wide format, see example package tidyr (pivot_wider(), pivot_longer()) function wideToLong() package eatTools. See section 1.1 details reshaping examples. lsa contains following variables: year: year assessment (2010 2015) idstud: individual student identifier; data set contains 11,637 persons overall idclass: class identifier; data set contains 432 classes overall wgt: sampling weight jkzone: jackknife zone jkrep: jackknife replicate imp: number imputation (1, 2, 3) nest: number nest (nested imputation yet considered , see examples repMean() details) country: federal state student stems sex: students sex (male, female) ses: socio economical status mig: migration background domain: competence domain (listening reading) score: point estimate (e.g., plausible value) corresponding imputation domain. According PISA, scale normed mean 500 standard deviation 100 comp: competence level 5 distinct levels according pre-defined cut scores. “1” corresponds lowest competence level, “5” corresponds highest competence level failMin: student fail achieve minimum standard? passReg: student achieve regular standard? passOpt: student achieve optimal standard? leScore: linking error according score variable leComp: linking error according comp variable leFailMin: linking error according failMin variable lePassReg: linking error according passReg variable lePassOpt: linking error according passOpt variable lsa includes 77,000 observations. Actual large scale assessment data, however, much observations. lsa represents small section 3 imputations (instead 10 used PISA), 3 federal states (PISA includes 35 OECD countries), two domains. variables labels, stored attributes: nested imputations considered , reduce data first nest:","code":"library(eatRep) data(lsa, package=\"eatRep\") str(lsa, give.attr = FALSE) ## 'data.frame':    77322 obs. of  25 variables: ##  $ year     : num  2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ... ##  $ idstud   : Factor w/ 11655 levels \"P00001\",\"P00002\",..: 1 1 1 1 1 1 2 2 2 2 ... ##  $ idclass  : Factor w/ 432 levels \"C001\",\"C002\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ wgt      : num  2.6 2.6 2.6 2.6 2.6 ... ##  $ L2wgt    : num  2.43 2.43 2.43 2.43 2.43 ... ##  $ L1wgt    : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ jkzone   : num  22 22 22 22 22 22 22 22 22 22 ... ##  $ jkrep    : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ imp      : num  3 2 1 1 2 3 2 3 2 1 ... ##  $ nest     : num  1 2 2 1 1 2 2 2 1 2 ... ##  $ country  : Factor w/ 3 levels \"countryA\",\"countryB\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ sex      : Factor w/ 2 levels \"female\",\"male\": 2 2 2 2 2 2 2 2 2 2 ... ##  $ ses      : num  56 56 56 56 56 56 32.5 32.5 32.5 32.5 ... ##  $ mig      : logi  TRUE TRUE TRUE TRUE TRUE TRUE ... ##  $ domain   : Factor w/ 2 levels \"listening\",\"reading\": 1 1 1 1 1 1 2 2 2 2 ... ##  $ score    : num  366 366 425 551 485 ... ##  $ comp     : num  1 1 2 3 3 3 3 3 3 3 ... ##  $ failMin  : num  1 1 0 0 0 0 0 0 0 0 ... ##  $ passReg  : num  0 0 0 1 1 1 1 1 1 1 ... ##  $ passOpt  : num  0 0 0 0 0 0 0 0 0 0 ... ##  $ leScore  : num  1.22 1.22 1.22 1.22 1.22 ... ##  $ leComp   : num  0.00262 0.00262 0.0022 0.00155 0.00155 ... ##  $ leFailMin: num  0.00262 0.00262 0.00262 0.00262 0.00262 ... ##  $ lePassReg: num  0.00482 0.00482 0.00482 0.00482 0.00482 ... ##  $ lePassOpt: num  0.00059 0.00059 0.00059 0.00059 0.00059 ... attributes(lsa[,\"year\"]) ## $varLabel ## [1] \"year of assessment (2010 or 2015)\" bt <- lsa[which(lsa[,\"nest\"] == 1),]"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"excursus-reshape-imputed-data-from-wide-into-long-format","dir":"Articles","previous_headings":"1. Example data","what":"1.1 Excursus: reshape imputed data from wide into long format","title":"Replication analyses with eatRep","text":"Institutions like PISA provide imputed data wide format. row data matrix represents one person. eatRep, however, needs long format. (Without imputations, procedure necessary.) Wide format data stores different imputations variable different columns. number imputations stored explicit variable results number additional columns per variable. Long format data stores different imputations variable additional rows. variable like imp defines number imputation. reshape2, tidyr data.table provide functions reshaping. Moreover, eatTools provides wideToLong() function easy reshaping required long format. illustrate functionality help wide format exemplary data data.timss3 BIFIEsurvey package: Data contains 4668 rows according 4668 persons. following variables considered reshaping: IDSTUD: individual student identifier TOTWGT: weighting variable JKZONE: jackknife zone JKREP: jackknife replicate female: students sex (1 = female; 0 = male) books: number books home lang: language home (often language used test spoken home?) migrant: migration background ASMMAT1: first imputation (first plausible value) math competence ASMMAT2: second imputation (second plausible value) math competence ASMMAT3: third imputation (third plausible value) math competence ASMMAT4: fourth imputation (fourth plausible value) math competence ASMMAT5: fifth imputation (fifth plausible value) math competence ASSSCI1: first imputation (first plausible value) science competence ASSSCI2: second imputation (second plausible value) science competence ASSSCI3: third imputation (third plausible value) science competence ASSSCI4: fourth imputation (fourth plausible value) science competence ASSSCI5: fifth imputation (fifth plausible value) science competence TIMSS data wide format, imputation variable exists. contrast long format, can easily see variables imputed (ASMMAT occurs five times), (female occurs ). reshaping, number imputations must constant across imputed variables—hence, wideToLong() used nested imputed data. wideToLong() needs know variables used analyses—remaining variables can ignored. functionality differentiates imputed non-imputed variables: non-imputed variables can defined single character string, whereas imputed variables defined named list one character strings. example, variable math consists five imputations ASMMAT1, ASMMAT2, ASMMAT3, ASMMAT4, ASMMAT5. Variable science also consists five imputations, ASSSCI1, ASSSCI2, ASSSCI3, ASSSCI4, ASSSCI5. Resulting data timssLong now suitable eatRep analyses. many imputations (e.g., 15), specifying character strings straightforward using paste() paste0() function: Alternatively, reshaping can performed melt() data.table package:","code":"data(data.timss3, package=\"BIFIEsurvey\") str(data.timss3, give.attr = FALSE) ## 'data.frame':    4668 obs. of  20 variables: ##  $ IDSTUD : num  4e+08 4e+08 4e+08 4e+08 4e+08 ... ##  $ TOTWGT : num  17.5 17.5 17.5 17.5 17.5 ... ##  $ JKZONE : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ JKREP  : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ female : num  1 0 1 1 1 1 1 1 0 0 ... ##  $ books  : num  3 3 5 3 3 2 4 3 3 4 ... ##  $ lang   : num  1 1 1 1 1 1 1 1 1 1 ... ##  $ migrant: num  0 0 0 0 0 0 0 0 0 0 ... ##  $ scsci  : num  NA 2 2 1 2 3 2 2 1 1 ... ##  $ likesc : num  2 4 2 1 1 1 2 2 NA 1 ... ##  $ ASMMAT1: num  543 522 456 512 506 ... ##  $ ASSSCI1: num  600 512 497 584 533 ... ##  $ ASMMAT2: num  557 533 462 510 563 ... ##  $ ASSSCI2: num  578 519 545 614 568 ... ##  $ ASMMAT3: num  506 557 445 531 530 ... ##  $ ASSSCI3: num  570 554 528 569 564 ... ##  $ ASMMAT4: num  524 511 473 497 488 ... ##  $ ASSSCI4: num  560 506 550 597 483 ... ##  $ ASMMAT5: num  578 546 457 528 583 ... ##  $ ASSSCI5: num  607 565 546 623 578 ... library(eatTools) timssLong <- eatTools::wideToLong(datWide = data.timss3,               noImp = c(\"IDSTUD\", \"TOTWGT\", \"JKZONE\", \"JKREP\", \"female\"),               imp = list ( math = c(\"ASMMAT1\", \"ASMMAT2\", \"ASMMAT3\", \"ASMMAT4\", \"ASMMAT5\"),                         science = c(\"ASSSCI1\", \"ASSSCI2\", \"ASSSCI3\", \"ASSSCI4\", \"ASSSCI5\"))) timssLong <- eatTools::wideToLong(datWide = data.timss3,               noImp = c(\"IDSTUD\", \"TOTWGT\", \"JKZONE\", \"JKREP\", \"female\"),               imp = list ( math = paste0(\"ASMMAT\",1:5),                          science = paste0(\"ASSSCI\",1:5))) library(data.table) timssLong2<- data.table::melt(setDT(data.timss3),                  id = c(\"IDSTUD\", \"TOTWGT\", \"JKZONE\", \"JKREP\", \"female\"),                  measure = patterns(\"^ASMMAT\", \"^ASSSCI\"),                  value.name = c(\"math\", \"science\"), variable.name=\"imp\")"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"main-functions-of-eatrep","dir":"Articles","previous_headings":"","what":"2. Main functions of “eatRep”","title":"Replication analyses with eatRep","text":"four main functions can seen “replication variants” base R functions mean(), table(), quantile(), glm(): repMean(): computes means, standard deviations, mean differences, standard deviation differences repTable(): computes frequency tables differences thereof repQuantile() quantiles, percentiles, repGlm(): linear generalized linear regression models","code":""},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"mean-analysis","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.1 Mean analysis","title":"Replication analyses with eatRep","text":"first example, want compute means standard deviations (along standard errors) reading competencies several federal states one distinct time measurement (2010). bt contains data 2010 2015 well competencies reading listening, subset data set: now call repMean() reduced data set bt2010read: use country grouping variable—analyses computed country separately. Important: persons data must nested within grouping variable. true country; person belongs one federal state. another possible grouping variable, domain, case, one single person may worked items one domain. check whether persons nested within grouping variable, function isNested() lme4 package package can called: conduct analyses domains single call, recommend using loop, according “listening” “reading”. demonstrate usage section 2.5. collect results single data.frame can exported excel, example, reporting function report2() called. simplify graphical visualization results using eatPlot package, new reporting function called report2() introduced. interested tabular representation results, sufficient simply extract “plain” worksheet list object returned function. old reporting function still included package deprecated. argument add augments output additional columns. function know analysis “reading” competence. information incorporated output, add argument allows define one multiple additional columns scalar information character type, example: analysis includes one grouping variable (“country”) one competence domain (“reading”) without group comparisons. output therefore rather sparse. However, results can computed according one grouping variable. results computed country migration group, specified grouping variables: Frequently, one might interested group means also total mean. Hence, want know mean single country mean whole population. can repeat analysis two times, one including grouping variables one ignoring grouping variables, easier use one single call: argument Argument group.splits defines “hierarchy levels” analyses, indicating whether analysis conducted within across groups. number hierarchy levels always equals number grouping variables plus one. One grouping variable means two hierarchy levels, two grouping variables mean three levels, . Without grouping variables, one level, “zeroth” level, exists. zeroth level, differentiation takes place; statistics computed whole population. one grouping variable (country, example) two levels can defined: zeroth level, statistics computed whole population, first level, statistics computed countryA, countryB, countryC separately. two grouping variables (country migration background: mig), three hierarchy levels defined. entire group (zeroth level), statistics computed countryA, countryB, countryC (first level, according country), statistics computed migration background migration background (first level, according mig), second level, statistics separately computed migrants countryA, migrants countryB, migrants countryB, natives countryA, natives countryB, natives countryC. group.splits numeric vector contains desired hierarchy levels. Without specifying group.splits, highest hierarchy level considered analysis. Assume one grouping variable. group.splits = c(0,1) group.splits = 0:1 additionally computes statistics zeroth level. two grouping variables, group.splits = 1:2 computes statistics first second level. zeroth level omitted. yield statistics possible level, type group.splits = 0:x, “x” equals number grouping variables.","code":"bt2010     <- bt[which(bt[,\"year\"] == 2010),] bt2010read <- bt2010[which(bt2010[,\"domain\"] == \"reading\"),] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = \"country\", dependent = \"score\",             progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. lme4::isNested(bt2010[,\"idstud\"], bt2010[,\"country\"]) ## [1] TRUE lme4::isNested(bt2010[,\"idstud\"], bt2010[,\"domain\"]) ## [1] FALSE resReading <- report2(results, add = list(kb=\"reading\"))[[\"plain\"]] resReading <- report2(results, add = list(kb=\"reading\", year = \"2010\"))[[\"plain\"]] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"mig\"), dependent = \"score\",             progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = \"country\", group.splits = 0:1,             dependent = \"score\", progress = FALSE) ## 2 analyse(s) overall according to: 'group.splits = 0 1'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                     NA ##                2               1           country                   NA ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]]"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"group-differences-in-means","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.2 Group differences in means","title":"Replication analyses with eatRep","text":"boys girls significantly differ mean competencies? Bavarian students outperform Saxonian students “reading”? mean score Canadian students significantly OECD average? examples can distinguished regarding whether units, compared, share hierarchy level. Differences within hierarchy level (e.g., boys vs. girls) referred “group differences”. Differences (adjacent) hierarchy levels (e.g., Canadian vs. OECD average, Canada part OECD average) referred “cross-level differences”. following example deals group differences according sex—compare, whether boys girls significantly differ means: argument group.differences.defines grouping variable differences computed. Note one variable can specified group.differences., variable must also occur groups (may, however, contain variables). pairwise contrasts computed levels group.differences.-variable. grouping variable dichotomous two levels (boys, girls), one contrast (boys vs. girls) can defined. grouping variable polytomous three levels (example, country countryA, countryB, countryC), three contrasts computed (countryA vs. countryB, countryA vs. countryC, countryB vs. countryC). polytomous variable four levels defines six contrasts, . groups includes one variable, group.differences.defines variables group differences computed. sex differences computed country separately, consider following call: Compute sex differences country additionally whole group: Compute country differences within sex group additionally whole group:","code":"results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = \"sex\", group.differences.by = \"sex\",             dependent = \"score\", progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),             group.differences.by = \"sex\", dependent = \"score\", progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,             group.differences.by = \"sex\", dependent = \"score\", progress = FALSE) ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country                 <NA> ##                3               1               sex                  sex ##                4               2     country + sex                  sex ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,             group.differences.by = \"country\", dependent = \"score\", progress = FALSE) ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]]"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"cross-level-differences-in-means","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.3 cross-level differences in means","title":"Replication analyses with eatRep","text":"easiest case, assume one grouping variable (sex levels boys girls) two hierarchy levels—zeroth first level. Cross-level differences refer difference one group mean (e.g., boys mean) total mean. two grouping variables, cross-level differences can thought differences one distinct group higher-ranking hierarchy levels. Assuming two grouping variables (country three levels, migration background mig two levels), 23 cross-level differences theoretically possible: level 2 vs. level 1: migrants countryA vs. migrants migrants countryB vs. migrants migrants countryC vs. migrants natives countryA vs. natives natives countryB vs. natives natives countryC vs. natives migrants countryA vs. countryA migrants countryB vs. countryB migrants countryC vs. countryC natives countryA vs. countryA natives countryB vs. countryB natives countryC vs. countryC level 1 vs. level 0: migrants vs. whole population natives vs. whole population countryA vs. whole population countryB vs. whole population countryC vs. whole population level 2 vs. level 0: migrants countryA vs. whole population migrants countryB vs. whole population migrants countryC vs. whole population natives countryA vs. whole population natives countryB vs. whole population natives countryC vs. whole population cross-level difference “connects” two hierarchy levels. Hierarchy levels neighboring, difference equals 1. Levels 2 1 neighboring, levels 2 0 . compute cross-level differences, group.splits must specified numeric vector least two distinct elements. reduce number cross-level differences, argument cross.differences allows define pairs hierarchy levels cross-level differences computed. give example: Consider grouping variables country (3 levels) mig (2 levels). Means computed three hierarchy levels. Group differences computed country variable (e.g., countryA vs. countryB, countryA vs. countryC, countryB vs. countryC). Cross-level differences computed relation zeroth level, e.g. level 1 vs. level 0, level 2 vs. level 0. following command called: cross.differences requests list numeric vectors distinct elements . vector must consist two integers, specifying hierarchy levels cross-differences computed. simplicity, cross.differences = TRUE requests possible cross-level differences. Conversely, cross.differences = FALSE omits cross-level differences. Combining group.differences.cross.differences allows compute cross-level differences group differences, example, researchers want know whether difference “boys vs. girls” “countryA” differs difference “boys vs. girls” total population. Note explicitly assume heteroscedastic variance cross-level difference estimation setting hetero = TRUE clusters = \"idclass\": output data.frame created report2(), cross-level differences group differences marked entry crossDiff_of_groupDiff comparison column.","code":"results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,             group.differences.by = \"country\", cross.differences = list(c(0,1), c(0,2)),             dependent = \"score\", progress = FALSE) ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## Warning in repMeanList(datL = datL, a = a): Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,             group.differences.by = \"sex\", cross.differences = TRUE, dependent = \"score\",             progress = FALSE, clusters = \"idclass\", hetero = TRUE) ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country                 <NA> ##                3               1               sex                  sex ##                4               2     country + sex                  sex ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## Compute cross level differences using 'wec' method. Assume heteroscedastic variances. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 32 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 60 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 40 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 91 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported."},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"statistical-remarks","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.4 Statistical remarks","title":"Replication analyses with eatRep","text":"cross-level differences, groups independent—comparing countryA whole population, one must consider countryA part whole population. Hence, t test appropriate. eatRep supports “weighted effect coding” (Grotenhuis et al., 2017; Weirich et al., 2021) replication methods (e.g, bootstrap), “weighted effect coding” (wec) default. Alternative methods can chosen crossDiffSE argument. method old uses inappropriate t test used. method maintained package provide compatibility older versions.","code":""},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"trend-analyses","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.5 Trend analyses","title":"Replication analyses with eatRep","text":"general, trends just group differences. groups distinct, persons nested within trend variable (person belongs solely one point time). major factor distinguishing trends “conventional” group differences item sample: group differences, item sample usually identical, trends, necessarily case. Moreover, comparisons across different points time run risk affected differential item functioning (DIF) item parameter drift (IPD). DIF can considered random, incorporated computation standard errors trend estimates. standard error trend estimates computed, eatRep allows take “linking error” according differently functioning items account. computing trends, analysis conducted cohorts (example, 2010 2015) separately. Afterwards, combination grouping variables, difference m‾2015−m‾2010\\bar{m}_{2015}-\\bar{m}_{2010} estimated. standard error difference : SEtrend=SE20102+SE20152+SElink2.\\begin{equation} SE_{trend}=\\sqrt{SE_{2010}^2+SE_{2015}^2+SE_{link}^2}.  \\end{equation} Trends can computed simple means, group differences, cross-level differences. illustration last analysis now repeated additional trend estimation. former used data object bt2010read used longer 2010 data included. use “reading competence” 2010 2015 subsetting bt data. function call, trend variable trend = \"year\" well linking error linkErr = \"leScore\" defined. Without specifying linkErr argument, linking error defaulted 0.","code":"btread  <- bt[which(bt[,\"domain\"] == \"reading\"),] results <- repMean(datL = btread, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,             group.differences.by = \"country\", cross.differences = list(c(0,1), c(0,2)),             dependent = \"score\", trend = \"year\", linkErr = \"leScore\", progress = FALSE) ##  ## Trend group: '2010' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ## Warning in repMeanList(datL = datL, a = a): Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. ##  ## ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. res     <- report2(results, add = list(kb=\"reading\"))[[\"plain\"]] ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported."},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"loops-across-non-nested-grouping-variables","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.6 Loops across non-nested (grouping) variables","title":"Replication analyses with eatRep","text":"Arguments groups group.splits allow analyze different groups different hierarchy levels just one single call. Alternatively, repMean() may called two times, without grouping variable(s), one additional grouping variable(s). argument groups requires individuals nested within grouping variables. Individuals, however, nested within competence domains (“reading” “listening”)—domain used grouping variable. Alternatively, domains analyzed one single call, additional outer loop necessary. demonstrate procedure exemplary data bt, containing domains “reading” “listening”. example , analyze group, cross-level, trend differences. -loop around repMean splits data two subsets analyzed consecutively. results object list two elements, “listening” “reading”. reporting function must called two list elements separately. now see argument add can help distinguish resulting data.frames. First, processing demonstrated without using loop: Using loop shortens call, especially two competence domains used:","code":"results <- by(data = bt, INDICES = bt[,\"domain\"], FUN = function ( subsample) {            repMean(datL = subsample, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                      repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),                      group.splits = 0:2, group.differences.by = \"country\",                      cross.differences = list(c(0,1), c(0,2)), dependent = \"score\",                      trend = \"year\", linkErr = \"leScore\", progress = FALSE) } ) ##  ## Trend group: '2010' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ## Warning in repMeanList(datL = datL, a = a): Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. ## ##  ## Trend group: '2010' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 4 analyse(s) overall according to: 'group.splits = 0 1 2'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by ##                1               0                                   <NA> ##                2               1           country              country ##                3               1               sex                 <NA> ##                4               2     country + sex              country ##  ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ## Warning in repMeanList(datL = datL, a = a): Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## Note: No linking error was defined. Linking error will be defaulted to '0'. names(results) ## [1] \"listening\" \"reading\" resultsListening <- report2(results[[\"listening\"]], add = list(kb = \"listening\"))[[\"plain\"]] ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. resultsReading   <- report2(results[[\"reading\"]], add = list(kb = \"reading\"))[[\"plain\"]] ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. allResults1      <- rbind (resultsListening, resultsReading) allResults2      <- lapply(names(results), FUN = function ( x ) {                             report2(results[[x]], add = list(kb=x))[[\"plain\"]]}) ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. ## Warning in FUN(X[[i]], ...): Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. allResults2      <- do.call(\"rbind\", allResults2)"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"adjusted-means","dir":"Articles","previous_headings":"2. Main functions of “eatRep”","what":"2.7 Adjusted means","title":"Replication analyses with eatRep","text":"eatRep also allows compute “adjusted” means (Mayer et al., 2016; Nachtigall et al., 2008). elaborate theoretical issues adjusted means—broadly speaking, unadjusted comparisons two countries, say, Japan Vietnam, may difficult interpret, countries differ substantially terms mean socio-economical status, migration background, background variables. Adjusted means can thought weighted means answer question: countries still differ mean competencies, distribution background variables equal? researcher free select background demographic variables chosen adjustment. demonstrate computation adjusted means domain “reading” 2010, adjust sex, migration background (mig) socio-economical status (ses). variables selected adjustment must numeric. polytomous variables (e.g., language home: “german”, “german another language”, “another language”) dichotomous indicator variables must generated beforehand. following example, transform non-numeric adjustment variables sex mig numeric. Please note , date, cross-level differences adjusted means can computed using methods old. zeroth hierarchy level, adjustment takes place. distribution background variables total population used reference adjusted group means, adjusted population mean equal unadjusted population mean. trends computed adjusted means, procedure sketched adopted without ado. adjusted mean countryA 2015 compared adjusted mean countryA 2010, reference group longer total population (e.g., countries). Unadjusted means depend specific research questions, adjusted means, research questions matters: countryA 2015 differ countryB 2015? countryA 2010 differ countryA 2015? questions require different adjustment approaches. previous section, adjustment one time measurement sketched: Japan still differ Vietnam, distribution background variables equivalent? trend analyses, research question : differences 2010 2015 Japan, composition students according demographic variables changed? package eatRep differentiate types research questions. compute adjusted trends, formerly known trend variable year must used grouping variable. adjusted trends different groups estimated, subsetting according groups must done hand via outer loop. incorporation linking errors, desired, must done hand likewise. following example illustrates procedure. standard error trend estimate computed square root sum squared standard errors 2010, 2015 link:","code":"sapply(bt2010read[,c(\"sex\", \"mig\", \"ses\")], class) ##       sex       mig       ses  ##  \"factor\" \"logical\" \"numeric\" bt2010read[,\"sexnum\"] <- car::recode(bt2010read[,\"sex\"], \"'male'=0; 'female'=1\",                           as.factor = FALSE) bt2010read[,\"mignum\"] <- as.numeric(bt2010read[,\"mig\"]) results <- repMean(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",             repInd = \"jkrep\", imp=\"imp\", groups = \"country\", group.splits = 0:1,             cross.differences = TRUE, adjust = c(\"sexnum\", \"mignum\", \"ses\"),             dependent = \"score\", progress = FALSE) ## Warning in repMeanList(datL = datL, a = a): To date, for adjusted means, cross-level differences can only be computed with method 'old'. Set 'crossDiffSE' to 'old'. ## 2 analyse(s) overall according to: 'group.splits = 0 1'. ##   ##  analysis.number hierarchy.level groups.divided.by group.differences.by adjust ##                1               0                                     NA  FALSE ##                2               1           country                   NA   TRUE ##  ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res <- report2(results, add = list( kb=\"reading\"))[[\"plain\"]] btread  <- bt[which(bt[,\"domain\"] == \"reading\"),] btread[,\"sexnum\"] <- car::recode(btread[,\"sex\"], \"'male'=0; 'female'=1\", as.factor = FALSE) btread[,\"mignum\"] <- as.numeric(btread[,\"mig\"]) btread[,\"year\"] <- as.integer(btread[,\"year\"]) results <- by(data = btread,  INDICES = btread[,\"country\"], FUN = function(sub.dat) {            res <- repMean(datL = sub.dat, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                    repInd = \"jkrep\", imp=\"imp\", groups = c(\"year\"),                    adjust = c(\"sexnum\", \"mignum\", \"ses\"), dependent = \"score\",                   progress = FALSE)            res <- report2(res, add = list( kb=\"reading\",                            country= as.character(sub.dat[1,\"country\"])))[[\"plain\"]]            res[,\"trend\"]   <- diff(res[,\"est\"])            res[,\"trendSE\"] <- sqrt(sum(res[,\"se\"]^2) + unique(sub.dat[,\"leScore\"])^2)            return(res)}) ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 62 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 65 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 48 replicate weights according to JK2 procedure. results <- do.call(\"rbind\", results)"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"frequency-analyses-reptable","dir":"Articles","previous_headings":"","what":"3. Frequency analyses (repTable)","title":"Replication analyses with eatRep","text":"Univariate frequency analyses polytomous variables can thought mean analyses dichotomous indicator variables. repTable() necessary —example, can redefine 5-level polytomous variable five dichotomous indicators call repMean() five times. main differences frequency mean analyses underlying statistic group differences: mean analyses typically uses t test independent samples (e.g., “Differ males females mean reading competencies?”). Frequency tables, however, use χ2\\chi^2 tests, example (“Differ males females distribution competence levels?”). theory, can test competence level 1, 2, 3, 4, 5 separate t test, whether males females differ. comparisons, however, independent—Bonferroni correction might appropriate . following, variants sketched: second example, group comparisons conducted applying five separate t tests. country single competence level, repTable() checks whether distribution differs males females. Technically, repMean() called five times consecutively. repTable(), computation cross-level differences trends works analogously repMean().","code":"### first example: group comparisons with a chi^2-Test: we check for each country  ### whether the distribution of competence levels differs between males and females freq1 <- repTable(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),           group.differences.by = \"sex\", cross.differences = FALSE, dependent = \"comp\",           chiSquare = TRUE, progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res1  <- report2(freq1, add = list( kb = \"reading\"))[[\"plain\"]] freq2 <- repTable(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",           repInd=\"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.differences.by = \"sex\",           cross.differences = FALSE, dependent = \"comp\", chiSquare = FALSE, progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res2  <- report2(freq2, add = list( kb = \"reading\"))[[\"plain\"]]"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"looping-across-several-dependent-variables","dir":"Articles","previous_headings":"3. Frequency analyses (repTable)","what":"3.1 Looping across several dependent variables","title":"Replication analyses with eatRep","text":"Section 2.5 demonstrates use () loops analyze one domain one single call. principle works several dependent variables within one domain. Suppose several dichotomous criteria (e.g. “failed reach minimal standard”, “pass regular standard”, “pass optimal standard”), represented several variables. lapply() loop ca applied : reporting function report() must called three times, likewise lapply() loop:","code":"### abhaengige Variablen definieren DVs   <- c(\"failMin\", \"passReg\", \"passOpt\") freq3 <- lapply(DVs, FUN = function (dv) {           repTable(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",              repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),              group.differences.by = \"sex\", cross.differences = FALSE,              dependent = dv, progress = FALSE) }) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. allResults3     <- do.call(\"rbind\", lapply(freq3, report))"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"nested-loops","dir":"Articles","previous_headings":"3. Frequency analyses (repTable)","what":"3.2 Nested loops","title":"Replication analyses with eatRep","text":"types loops (across non-nested grouping variables across several dependent variables) may combined. following example, want analyze three dependent variables two domains. Hence, two-stage loop 3×2=63\\times 2=6 analyses necessary: convert results user-friendly format: combination two loops also works trend analyses. Please note dependent variable potentially linking error. , one solution store variable name along linking error data.frame use apply() loop: convert results user-friendly format:","code":"DVs   <- c(\"failMin\", \"passReg\", \"passOpt\") freq4 <- lapply(DVs, FUN = function (dv) {           f4 <- by ( data = bt2010, INDICES = bt2010[,\"domain\"], FUN = function (sub.dat) {                repTable(datL = sub.dat, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                           repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),                           group.differences.by = \"sex\", cross.differences = FALSE,                           dependent = dv, progress = FALSE)})}) ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. allResults4  <- lapply(freq4, FUN = function (av) {                         do.call(\"rbind\", lapply(names(av), FUN = function ( x ) {                           report2(av[[x]], add = list(kb=x))[[\"plain\"]]}))}) allResults4  <- do.call(\"rbind\", allResults4) ### two-stage nested loop with trend analysis ### first we define the dependent variables (dv) and their linking errors (le) DVs   <- data.frame ( dv = c(\"failMin\", \"passReg\", \"passOpt\"),                        le = c(\"leFailMin\", \"lePassReg\", \"lePassOpt\"),                        stringsAsFactors = FALSE) freq5 <- apply(DVs, MARGIN = 1, FUN = function (depVars) {           f4 <- by ( data = bt, INDICES = bt[,\"domain\"], FUN = function (sub.dat) {                repTable(datL = sub.dat, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                           repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"),                           group.differences.by = \"sex\", cross.differences = FALSE,                           trend = \"year\", dependent = depVars[[\"dv\"]],                          linkErr = depVars[[\"le\"]], progress = FALSE)})}) ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. ## ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 2'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. allResults5 <- lapply(freq5, FUN = function (av) {                         do.call(\"rbind\", lapply(names(av), FUN = function ( x ) {                            report2(av[[x]], add = list(kb=x))[[\"plain\"]]}))}) ## Warning in FUN(X[[i]], ...): Found 6 missing linking errors for dependent variable 'failMin' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases. ## Warning in FUN(X[[i]], ...): Found 6 missing linking errors for dependent variable 'passReg' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases. ## Warning in FUN(X[[i]], ...): Found 6 missing linking errors for dependent variable 'passOpt' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases. allResults5 <- do.call(\"rbind\", allResults5)"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"analyses-of-ranges-repquantile","dir":"Articles","previous_headings":"","what":"4. Analyses of ranges (repQuantile)","title":"Replication analyses with eatRep","text":"analyzing quartiles, quantiles percentiles, please note computation group differences supported yet. repQuantile requires specify probabilities via probs argument. following example illustrates usage function domain “reading” 2010 2015. compute 5., 10., 25., 75., 90., 95. percentile:","code":"btRead <- bt[which(bt[,\"domain\"] == \"reading\"),] quan   <- repQuantile(datL = btRead, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                 repInd = \"jkrep\", imp=\"imp\", groups = \"country\", trend = \"year\",                 dependent = \"score\", linkErr = \"leScore\",                 probs = c(.05, .1, .25, .75, .90, .95), progress = FALSE ) ##  ## Trend group: '2010' ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. ##  ##  ## Trend group: '2015' ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 73 replicate weights according to JK2 procedure. res    <- report(quan, add = list(domain = \"reading\"))"},{"path":"https://weirichs.github.io/eatRep/articles/eatRep.html","id":"regression-analyses-repglm","dir":"Articles","previous_headings":"","what":"5. Regression analyses (repGlm)","title":"Replication analyses with eatRep","text":"repGlm allows estimate linear logistic regression models. date, trend analyses incorporate linking errors. reporting function report() optionally allows print results console (printGlm set TRUE). first example, regression reading competence sex, SES estimated country separately. valid interpretation interaction effects, SES variable standardized within imputation: second example illustrates logistic regression. Whether regular standard passed (passReg) dependent variable. variable country now used predictor. output gives R2R^2 (linear regression models) well Nagelkerke’s R2R^2 (logistic regression models).","code":"bt2010read <- by(data=bt2010read, INDICES = bt2010read[,\"imp\"], FUN = function ( i ) {                  i[,\"ses_std\"] <- scale(i[,\"ses\"])[,1]                 return(i)}) bt2010read <- do.call(\"rbind\", bt2010read)               reg1   <- repGlm(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                 repInd = \"jkrep\", imp=\"imp\", groups = \"country\",  formula = score~sex*ses_std,                 family=gaussian(link=\"identity\"), progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 1'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res1   <- report2(reg1, add = list(domain = \"reading\"), printGlm = TRUE)[[\"plain\"]] ##        Trend group: 'noTrend'. ##             groups: type = point; country = countryA; row = 1; id = 14574361_1 ##             domain: reading ## dependent Variable: score ##   ##         parameter     est    se t.value p.value sig ## 1     (Intercept) 505.837 4.428 114.243   0.000 *** ## 2         ses_std  23.697 3.876   6.114   0.000 *** ## 3         sexmale   8.677 5.594   1.551   0.121     ## 4 sexmale:ses_std   4.109 5.527   0.743   0.457     ##  ##             R-squared: 0.115; SE(R-squared): NA ## 1034 observations and 1030 degrees of freedom. ## ------------------------------------------------------------------ ##             groups: type = point; country = countryB; row = 4; id = 14574361_4 ##             domain: reading ## dependent Variable: score ##   ##         parameter     est    se t.value p.value sig ## 1     (Intercept) 499.044 4.624 107.934   0.000 *** ## 2         ses_std  28.344 4.637   6.113   0.000 *** ## 3         sexmale   7.918 7.804   1.015   0.311     ## 4 sexmale:ses_std   7.598 5.024   1.512   0.131     ##  ##             R-squared: 0.181; SE(R-squared): NA ## 959 observations and 955 degrees of freedom. ## ------------------------------------------------------------------ ##             groups: type = point; country = countryC; row = 7; id = 14574361_7 ##             domain: reading ## dependent Variable: score ##   ##         parameter     est    se t.value p.value sig ## 1     (Intercept) 525.240 3.788 138.663   0.000 *** ## 2         ses_std  24.083 5.246   4.591   0.000 *** ## 3         sexmale  15.108 5.289   2.856   0.004  ** ## 4 sexmale:ses_std   0.879 7.460   0.118   0.906     ##  ##             R-squared: 0.096; SE(R-squared): NA ## 1086 observations and 1082 degrees of freedom. reg2   <- repGlm(datL = bt2010read, ID=\"idstud\", wgt=\"wgt\", type=\"jk2\", PSU=\"jkzone\",                 repInd = \"jkrep\", imp=\"imp\", formula = passReg~country*ses_std,                 family=binomial(link=\"logit\"), progress = FALSE) ## 1 analyse(s) overall according to: 'group.splits = 0'. ## Assume unnested structure with 3 imputations. ## Create 92 replicate weights according to JK2 procedure. res2   <- report2(reg2, add = list(domain = \"reading\"), printGlm = TRUE)[[\"plain\"]] ##        Trend group: 'noTrend'. ##             groups: type = point; row = 1; id = 14575099_1 ##             domain: reading ## dependent Variable: passReg ##   ##                 parameter    est    se t.value p.value sig ## 1             (Intercept) -0.227 0.115  -1.972   0.049   * ## 2         countrycountryB -0.206 0.156  -1.317   0.188     ## 3 countrycountryB:ses_std  0.097 0.159   0.613   0.540     ## 4         countrycountryC  0.465 0.141   3.305   0.001 *** ## 5 countrycountryC:ses_std -0.086 0.142  -0.604   0.546     ## 6                 ses_std  0.609 0.082   7.401   0.000 *** ##  ##             R-squared: 0.116; SE(R-squared): NA ## 3079 observations and 3073 degrees of freedom."},{"path":[]},{"path":"https://weirichs.github.io/eatRep/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sebastian Weirich. Author, maintainer. Martin Hecht. Author. Karoline Sachse. Author. Benjamin Becker. Author. Edna Grewers. Contributor.","code":""},{"path":"https://weirichs.github.io/eatRep/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Weirich S, Hecht M, Sachse K, Becker B (2025). eatRep: Educational Assessment Tools Replication Methods. R package version 0.15.0, https://weirichs.github.io/eatRep/, https://github.com/weirichs/eatRep.","code":"@Manual{,   title = {eatRep: Educational Assessment Tools for Replication Methods},   author = {Sebastian Weirich and Martin Hecht and Karoline Sachse and Benjamin Becker},   year = {2025},   note = {R package version 0.15.0, https://weirichs.github.io/eatRep/},   url = {https://github.com/weirichs/eatRep}, }"},{"path":[]},{"path":"https://weirichs.github.io/eatRep/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Educational Assessment Tools for Replication Methods","text":"eatRep (Educational Assessment Tools Replication Methods) provides functions compute basic statistic operations (means, standard deviations, frequency tables, percentiles generalized linear models) complex survey designs comprising multiple imputed variables /clustered sampling structure deserve special procedures least estimating standard errors.","code":""},{"path":"https://weirichs.github.io/eatRep/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Educational Assessment Tools for Replication Methods","text":"","code":"# Install eatRep from GitHub via devtools::install_github(\"weirichs/eatRep\")"},{"path":"https://weirichs.github.io/eatRep/index.html","id":"view-package-documentation","dir":"","previous_headings":"","what":"View package documentation","title":"Educational Assessment Tools for Replication Methods","text":"","code":"library(eatRep) ### View package documentation package?eatRep"},{"path":"https://weirichs.github.io/eatRep/index.html","id":"exemplary-analysis","dir":"","previous_headings":"","what":"Exemplary analysis","title":"Educational Assessment Tools for Replication Methods","text":"following example illustrates computation mean educational outcomes three fictitious countries. Data stem large-scale assessment reading competencies assessed using dichotomous items (true/false). outcome considered latent, plausible values drawn examinee. Plausible values can considered multiple imputations inherently unobserved latent outcome. within-person variance plausible values used determine measurement error. sampling, classes drawn instead individuals. sample clustered , computation sampling error involves replication methods.","code":"library(eatRep) ### compute group means for multiple imputed data in a clustered structure ### from a large-scale assessment survey data(lsa)  ### Example 1: only means, SD and variances for each country ### We only consider domain 'reading' rd     <- lsa[which(lsa[,\"domain\"] == \"reading\"),]  ### We only consider the first \"nest\". rdN1   <- rd[which(rd[,\"nest\"] == 1),]  ### First, we only consider year 2010 rdN1y10<- rdN1[which(rdN1[,\"year\"] == 2010),]  ### mean estimation means1 <- repMean(datL = rdN1y10, ID=\"idstud\", wgt=\"wgt\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = \"country\", dependent = \"score\",           na.rm=FALSE, doCheck=TRUE, engine = \"BIFIEsurvey\") ### reporting function: the function does not know which content domain is being considered, ### so the user may add new columns in the output using the 'add' argument res1   <- report(means1, add = list(domain = \"reading\"))"},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks compatibility of linking errors with GADS data bases. — checkLEs","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"function checks linking error data.frame compatible multiple trend eatGADS data bases.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"","code":"checkLEs(filePaths, leDF)"},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"filePaths Character vectors least two paths eatGADS db files. leDF Linking error data.frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"function inspects whether linking error variables correspond variables eatGADS data base key variables also correspond existing variables trend eatGADS data bases.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"Returns report list.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/checkLEs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Checks compatibility of linking errors with GADS data bases. — checkLEs","text":"","code":"trenddat1 <- system.file(\"extdata\", \"trend_gads_2010.db\", package = \"eatGADS\") trenddat2 <- system.file(\"extdata\", \"trend_gads_2015.db\", package = \"eatGADS\") trenddat3 <- system.file(\"extdata\", \"trend_gads_2020.db\", package = \"eatGADS\") load(system.file(\"extdata\", \"linking_error.rda\", package = \"eatRep\")) check1 <- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr) #> The following variables have linking errors but are not variables in data base 1: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 2: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 3: 'value', 'valueTransfBista' check2 <- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr[1:14,]) #> The following variables have linking errors but are not variables in data base 1: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 2: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 3: 'value', 'valueTransfBista' #> Warning: Number of trend levels do not match: Expect 3 trend levels in data base ('filePaths' has length 3). 2 trend levels for linking errors ('2010', '2015') found."},{"path":"https://weirichs.github.io/eatRep/reference/generateRandomJk1Zones.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","title":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","text":"Function adds randomly generated jackknife-1 zones data.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/generateRandomJk1Zones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","text":"","code":"generateRandomJk1Zones (datL, unit, nZones, name = \"randomCluster\")"},{"path":"https://weirichs.github.io/eatRep/reference/generateRandomJk1Zones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","text":"datL Data frame containing least primary sampling unit variable unit Variable name column number primary sampling unit (.e.   student class identifier) nZones integer: number jackknife zones. Note: umber jackknife   zones must exceed number distinct sampling units name New name jackknife-zone variable data set","code":""},{"path":"https://weirichs.github.io/eatRep/reference/generateRandomJk1Zones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","text":"original data additional column jackknife-zone variable","code":""},{"path":"https://weirichs.github.io/eatRep/reference/generateRandomJk1Zones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates random jackknife-1 zones based on sampling units in the data set. — generateRandomJk1Zones","text":"","code":"data(lsa)  ### We only consider year 2010 lsa10<- lsa[which(lsa[,\"year\"] == 2010),] lsa10<- generateRandomJk1Zones(datL = lsa10, unit=\"idclass\", nZones = 50) #> Warning: Number of zones (50) is large compared to the number of distinct units (219)."},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"(nested) multiple imputations, determination coefficient \\(R^2\\) computed imputed data set pooled afterwards. pool.R2 provide pooling routines according Harel (2009). function requires \\(R^2\\) coefficients multiple imputed analyses already available.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"","code":"pool.R2 ( r2, N, verbose = TRUE )"},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"r2 multiple imputed data, numeric vector \\(R^2\\) values. nested multiple imputed data, list numeric vectors \\(R^2\\) values. number list elements must correspond number nests. number \\(R^2\\) values within list element must equal must correspond number imputations within nest. N Optional: sample size imputed data set. necessary standard error pooled \\(R^2\\) computed. structure N object must correspond structure r2 object. See examples details. verbose Optional: Print additional messages console?","code":""},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"Returns data.frame one two columns contains pooled \\(R^2\\) value optionally standard error.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"Harel, O. (2009): estimation \\(R^2\\) adjusted \\(R^2\\) incomplete data   sets using multiple imputation. Journal Applied Statistics. 36, 10, 1109–1118.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/pool.R2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute \\(R^2\\) in multiple imputed and nested multiple imputed data — pool.R2","text":"","code":"# multiple imputation, assume that the regression analysis was fitted for five imputed data sets, # resulting in five R^2 values. Assume sample sizes of 340 r2 <- c(0.12395, 0.15261, 0.16125, 0.11029, 0.1871) Ns <- rep(340,5) pool.R2 ( r2=r2, N=Ns) #>    m.pooled   se.pooled #> 1 0.1461977 0.002639094 # without standard error pool.R2 ( r2=r2) #> No sample sizes given. Will not compute standard error of pooled R squared. #>    m.pooled #> 1 0.1461977 # nested multiple imputation r2 <- list(nest1 = c(0.12395, 0.15261, 0.16125, 0.11029, 0.1871),            nest2 = c(0.10603, 0.08876, 0.09248, 0.13331, 0.1114),            nest3 = c(0.17228, 0.25203, 0.13132, 0.23331, 0.10069)) Ns <- lapply(1:3, FUN = function (x) {rep(290, 5)}) pool.R2 ( r2=r2, N=Ns) #>    m.pooled   se.pooled #> 1 0.1414264 0.007142926 # without standard error pool.R2 ( r2=r2) #> No sample sizes given. Will not compute standard error of pooled R squared. #>    m.pooled #> 1 0.1414264"},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":null,"dir":"Reference","previous_headings":"","what":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"Compute generalized linear models complex cluster designs multiple imputed variables based Jackknife (JK1, JK2) balanced repeated replicates (BRR) procedure. Conceptually, function combines replication methods methods multiple imputed data. Technically, wrapper svyglm function survey package.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"","code":"repGlm(datL, ID, wgt = NULL, type = c(\"none\", \"JK2\", \"JK1\", \"BRR\", \"Fay\"), PSU = NULL,         repInd = NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,         group.splits = length(groups), group.delimiter = \"_\",         cross.differences = FALSE, trend = NULL, linkErr = NULL, formula,         family=gaussian, forceSingularityTreatment = FALSE,         glmTransformation = c(\"none\", \"sdY\"), doCheck = TRUE, na.rm = FALSE,         poolMethod = c(\"mice\", \"scalar\"), useWec = FALSE,         scale = 1, rscales = 1, mse=TRUE, rho=NULL, hetero=TRUE,         se_type = c(\"HC3\", \"HC0\", \"HC1\", \"HC2\", \"CR0\", \"CR2\"),         clusters = NULL, crossDiffSE.engine= c(\"lavaan\", \"lm\"),         stochasticGroupSizes = FALSE, verbose = TRUE, progress = TRUE,         nCores=NULL)"},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"datL Data frame long format (.e. line represents one ID unit one imputation one nest) containing variables analysis. ID Variable name column number student identifier (ID) variable. ID variable must contain missing values. wgt Optional: Variable name column number weighting variable. weighting variable specified, cases equally weighted. type Defines replication method cluster replicates applied. Depending type, additional arguments must specified (e.g., PSU /repInd repWgt). PSU Variable name column number variable indicating primary sampling unit (PSU). jackknife procedure applied, PSU jackknife zone variable. NULL, cluster structure assumed standard errors computed according random sample. repInd Variable name column number variable indicating replicate ID. jackknife procedure, jackknife replicate variable. NULL, cluster structure assumed standard errors computed according random sample. repWgt Normally, replicate weights created repGlm directly PSU repInd variables. Alternatively, replicate weights included data.frame, specify variable names column number repWgt argument. nest Optional: name column number nesting variable. applies nested multiple imputed data sets. imp Optional: name column number imputation variable. applies multiple imputed data sets. groups Optional: vector names column numbers one grouping variables. group.splits Optional: groups defined, group.splits optionally specifies whether analysis done also whole group overlying groups. See examples details. group.delimiter Character string separates group names output frame. cross.differences Either list vectors, specifying pairs levels cross-level differences computed. Alternatively, TRUE, cross-level differences pairs levels computed. FALSE, cross-level differences computed. (see examples 2a, 3, 4 help file repMean function) trend Optional: name column number trend variable contains measurement time survey. Note: Levels grouping variables predictors must equal 'sub populations' partitioned discrete trend variable. repGlm computes differences pairwise contrasts defined trend variable levels. three measurement occasions, .e. 2010, 2015, 2020, contrasts (.e. trends) computed 2010 vs. 2015, 2010 vs. 2020, 2015 vs. 2020. linkErr Optional: name column number linking error variable. NULL, linking error 0 assumed trend estimation. formula Model formula, see help page glm details. family description error distribution link function used model. See help page glm details. forceSingularityTreatment Logical: Forces function use workaround handle singularities regression models. glmTransformation Optional: Allows transformation parameters linear regression logistic regression pooling. Useful compare parameters different glm models, see Mood (2010). Note: argument applies forceSingularityTreatment set 'TRUE'. doCheck Logical: Check data consistency analysis? TRUE groups insufficient data excluded analysis prevent subsequent functions crashing. na.rm Logical: cases missing values dropped? poolMethod pooling method used? “mice” method recommended. useWec Logical: use weighted effect coding? scale scaling constant variance, details, see help page svrepdesign survey package rscales scaling constant variance, details, see help page svrepdesign survey package mse Logical: TRUE, compute variances based sum squares around point estimate, rather mean replicates. See help page svrepdesign survey package details. rho Shrinkage factor weights Fay's method. See help page svrepdesign survey package details. hetero Logical: Assume heteroscedastic variance weighted effect coding? applies random samples, .e. replication analyses executed. se_type sort standard error sought cross level differences. applies crossDiffSE == \"wec\" hetero == TRUE crossDiffSE.engine == \"lm\". See help page lm_robust estimatr package details. clusters Optional: Variable name column number cluster variable. necessary weighted effecting coding performed using heteroscedastic variances. See help page lm_robust estimatr package details. crossDiffSE.engine Optional: Sort estimator used standard error estimation weighted effect coding regression. applies useWec == TRUE. date, lavaan allows stochastic group sizes. stochasticGroupSizes Logical: Assume stochastic group sizes using weighted effect coding regression categorical predictors? Note: date, lavaan allows stochastic group sizes. Stochastic group sizes assumed replication method (jackknife, BRR) applied. verbose Logical: Show analysis information console? progress Logical: Show progress bar console? nCores integer (default: NULL), number cores use parallel processing, engine = \"survey\". NULL, single core processing used.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"Function first creates replicate weights based PSU repInd variables according JK2 BRR procedure. According multiple imputed data sets, workbook several analyses created. function afterwards serves wrapper svyglm implemented survey package. results several analyses pooled according Rubin's rule, adapted nested imputations nest argument implies nested structure.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"list data frames long format. output can summarized using report function. first element list list either one (trend analyses) two (trend analyses) data frames least six columns . subpopulation denoted groups statement, dependent variable, parameter coefficient corresponding value given. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 analysis without sampling weights conducted, ‘modus’ takes value ‘jk2.unweighted’. analysis without replicates sampling weights conducted, ‘modus’ takes value ‘weighted’. parameter Denotes parameter regression model corresponding value given . Amongst others, ‘parameter’ column takes values ‘(Intercept)’ ‘gendermale’ ‘gender’ dependent variable, instance. See example 1 details. coefficient Denotes coefficient corresponding value given . Takes values ‘est’ (estimate) ‘se’ (standard error estimate). value value parameter estimate corresponding group. groups specified, columns denoted group names added data frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"te Grotenhuis, M., Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, ., & Konig, R. (2017). size matters: advantages weighted effect coding observational studies. International Journal Public Health. 62, 163–167.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repGlm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation. — repGlm","text":"","code":"### load example data (long format) data(lsa) ### use only the first nest bt         <- lsa[which(lsa[,\"nest\"] == 1),] ### use only data from 2010 bt2010     <- bt[which(bt[,\"year\"] == 2010),] ## use only reading data bt2010read <- bt2010[which(bt2010[,\"domain\"] == \"reading\"),]  ### Example 1: Computes linear regression from reading score on gender separately ### for each country. Assume no nested structure. mod1 <- repGlm(datL = bt2010read, ID = \"idstud\", wgt = \"wgt\", type = \"jk2\",         PSU = \"jkzone\", repInd = \"jkrep\", imp = \"imp\", groups = \"country\",         formula = score~sex, family =\"gaussian\") #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res1 <- report(mod1, printGlm = TRUE) #> Warning: `report()` was deprecated in eatRep 0.15.0. #> ℹ For the original behavior of report() please use eatRep version 0.14.7: #>   'https://cran.r-project.org/src/contrib/Archive/eatRep/' #>        Trend group: 'noTrend'. #>             groups: type = point; country = countryA; row = 1; id = 16055093_1 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value sig #> 1 (Intercept) 508.406 4.321 117.651   0.000 *** #> 2     sexmale   6.088 5.831   1.044   0.297     #>  #>             R-squared: 0.002; SE(R-squared): NA #> 1034 observations and 1032 degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryB; row = 4; id = 16055093_4 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value sig #> 1 (Intercept) 502.607 5.049  99.554   0.000 *** #> 2     sexmale  11.005 7.177   1.533   0.126     #>  #>             R-squared: 0.005; SE(R-squared): NA #> 959 observations and 957 degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryC; row = 7; id = 16055093_7 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value sig #> 1 (Intercept) 526.287 3.949 133.267   0.000 *** #> 2     sexmale  15.268 5.873   2.600   0.009  ** #>  #>             R-squared: 0.009; SE(R-squared): NA #> 1086 observations and 1084 degrees of freedom.  # \\donttest{ ### Example 2: Computes log linear regression from pass/fail on ses and gender ### separately for each country in a nested structure. Assuming equally weighted ### cases by omitting \"wgt\" argument dat  <- lsa[intersect(which(lsa[,\"year\"] == 2010), which(lsa[,\"domain\"] == \"reading\")),] mod2 <- repGlm(datL = dat, ID = \"idstud\", type = \"JK2\",  PSU = \"jkzone\",         repInd = \"jkrep\", imp = \"imp\", nest=\"nest\", groups = \"country\",         formula = passReg~sex*ses, family = quasibinomial(link=\"logit\")) #> Method 'mice' is not available for nested imputation. Switch to method 'scalar'. #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #>  res2 <- report(mod2, printGlm = TRUE) #>        Trend group: 'noTrend'. #>             groups: type = point; country = countryA; row = 1; id = 16055352_1 #> dependent Variable: passReg #>   #>     parameter    est    se t.value p.value  sig #> 1 (Intercept) -1.765 0.357  -4.949      NA <NA> #> 2         ses  0.027 0.005   4.929      NA <NA> #> 3     sexmale -0.055 0.443  -0.125      NA <NA> #> 4 sexmale:ses  0.004 0.008   0.435      NA <NA> #>  #>             R-squared: 0.098; SE(R-squared): 0.098 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryB; row = 4; id = 16055352_4 #> dependent Variable: passReg #>   #>     parameter    est    se t.value p.value  sig #> 1 (Intercept) -2.464 0.361  -6.834      NA <NA> #> 2         ses  0.033 0.007   4.697      NA <NA> #> 3     sexmale  0.179 0.528   0.339      NA <NA> #> 4 sexmale:ses  0.000 0.010   0.025      NA <NA> #>  #>             R-squared: 0.13; SE(R-squared): 0.13 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryC; row = 7; id = 16055352_7 #> dependent Variable: passReg #>   #>     parameter    est    se t.value p.value  sig #> 1 (Intercept) -1.373 0.313  -4.386      NA <NA> #> 2         ses  0.028 0.006   4.594      NA <NA> #> 3     sexmale  0.453 0.413   1.097      NA <NA> #> 4 sexmale:ses -0.003 0.008  -0.356      NA <NA> #>  #>             R-squared: 0.091; SE(R-squared): 0.091 #>  observations and  degrees of freedom.  ### Example 3: Like example 1, but without any replication methods ### trend estimation (without linking error) and nested imputation dat  <- lsa[which(lsa[,\"domain\"] == \"reading\"),] mod3 <- repGlm(datL = dat, ID = \"idstud\", wgt = \"wgt\", imp = \"imp\", nest = \"nest\",         groups = \"country\",  formula = score~sex, trend = \"year\") #> Method 'mice' is not available for nested imputation. Switch to method 'scalar'. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #> No sample sizes given. Will not compute standard error of pooled R squared. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. res3 <- report(mod3, printGlm = TRUE) #>        Trend group: '2010'. #>             groups: type = point; country = countryA; row = 1; id = 16055439_1; year = 2010 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 508.643 3.611 140.859      NA <NA> #> 2     sexmale   6.003 4.962   1.210      NA <NA> #>  #>             R-squared: 0.002; SE(R-squared): 0.002 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryB; row = 4; id = 16055439_4; year = 2010 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 503.053 4.483 112.221      NA <NA> #> 2     sexmale  10.068 6.164   1.633      NA <NA> #>  #>             R-squared: 0.004; SE(R-squared): 0.004 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryC; row = 7; id = 16055439_7; year = 2010 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 526.381 3.684 142.874      NA <NA> #> 2     sexmale  14.263 5.383   2.649      NA <NA> #>  #>             R-squared: 0.008; SE(R-squared): 0.008 #>  observations and  degrees of freedom. #> ============================================================================ #>        Trend group: '2015'. #>             groups: type = point; country = countryA; row = 1; id = 16055461_1; year = 2015 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 507.311 3.676 138.010      NA <NA> #> 2     sexmale   1.158 5.018   0.231      NA <NA> #>  #>             R-squared: 0; SE(R-squared): 0 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryB; row = 4; id = 16055461_4; year = 2015 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 492.666 4.757 103.563      NA <NA> #> 2     sexmale   6.548 6.390   1.025      NA <NA> #>  #>             R-squared: 0.002; SE(R-squared): 0.002 #>  observations and  degrees of freedom. #> ------------------------------------------------------------------ #>             groups: type = point; country = countryC; row = 7; id = 16055461_7; year = 2015 #> dependent Variable: score #>   #>     parameter     est    se t.value p.value  sig #> 1 (Intercept) 514.175 3.444 149.311      NA <NA> #> 2     sexmale  12.004 4.813   2.494      NA <NA> #>  #>             R-squared: 0.005; SE(R-squared): 0.005 #>  observations and  degrees of freedom. # }"},{"path":"https://weirichs.github.io/eatRep/reference/repLmer.html","id":null,"dir":"Reference","previous_headings":"","what":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","title":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","text":"Compute multilevel linear models complex cluster designs multiple imputed variables based Jackknife (JK1, JK2) procedure. Conceptually, function combines replication methods methods multiple imputed data. Technically, wrapper BIFIE.twolevelreg function BIFIEsurvey package. repLmer adds functionality trend estimation. Please note function suitable logistic logit/probit models.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repLmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","text":"","code":"repLmer(datL, ID, wgt = NULL, L1wgt=NULL, L2wgt=NULL, type = c(\"JK2\", \"JK1\"),             PSU = NULL, repInd = NULL, jkfac = NULL, rho = NULL, imp=NULL,             group = NULL, trend = NULL, dependent, formula.fixed, formula.random,             doCheck = TRUE, na.rm = FALSE, clusters, verbose = TRUE)"},{"path":"https://weirichs.github.io/eatRep/reference/repLmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","text":"datL Data frame long format (.e. line represents one ID unit one imputation one nest) containing variables analysis. ID Variable name column number student identifier (ID) variable. ID variable must contain missing values. wgt Optional: Variable name column number case weighting variable. weighting variable specified, cases equally weighted. L1wgt Name Level 1 weight variable. optional. provided, L1wgt calculated total weight (.e., wgt) L2wgt. L2wgt Name Level 2 weight variable type Defines replication method cluster replicates applied. Depending type, additional arguments must specified (e.g., PSU /repInd repWgt). PSU Variable name column number variable indicating primary sampling unit (PSU). jackknife procedure applied, PSU jackknife zone variable. NULL, cluster structure assumed standard errors computed according random sample. repInd Variable name column number variable indicating replicate ID. jackknife procedure, jackknife replicate variable. NULL, cluster structure assumed standard errors computed according random sample. jkfac Argument passed BIFIE.data.jack specifies factor multiplying jackknife replicate weights. rho Fay factor statistical inference. argument passed fayfac argument BIFIE.data.jack function BIFIEsurvey package. See corresponding help page details. convenience, rho = NULL (default) type = \"JK1\", BIFIE.data.jack called jktype=\"JK_GROUP\" fayfac = rho, \\(\\rho = (N_{cluster} - 1) \\times N_{cluster}^{-1}\\) imp Name column number imputation variable. group Optional: column number name one grouping variable. Note: contrast repMean, one grouping variable can specified. trend Optional: name column number trend variable contains measurement time survey. repLmer computes differences pairwise contrasts defined trend variable levels. three measurement occasions, .e. 2010, 2015, 2020, contrasts (.e. trends) computed 2010 vs. 2015, 2010 vs. 2020, 2015 vs. 2020. dependent Name column number dependent variable formula.fixed R formula fixed effects formula.random R formula random effects doCheck Logical: Check data consistency analysis? TRUE groups insufficient data excluded analysis prevent subsequent functions crashing. na.rm Logical: cases missing values dropped? clusters Variable name column number cluster variable. verbose Logical: Show analysis information console?","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repLmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","text":"list data frames long format. output can summarized using report function. first element list list either one (trend analyses) two (trend analyses) data frames least six columns . subpopulation denoted groups statement, dependent variable, parameter coefficient corresponding value given. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 analysis without sampling weights conducted, ‘modus’ takes value ‘jk2.unweighted’. analysis without replicates sampling weights conducted, ‘modus’ takes value ‘weighted’. parameter Denotes parameter regression model corresponding value given . Amongst others, ‘parameter’ column takes values ‘(Intercept)’ ‘gendermale’ ‘gender’ dependent variable, instance. See example 1 details. coefficient Denotes coefficient corresponding value given . Takes values ‘est’ (estimate) ‘se’ (standard error estimate). value value parameter estimate corresponding group. groups specified, columns denoted group names added data frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repLmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation. — repLmer","text":"","code":"### load example data (long format) data(lsa) ### use only the first nest, use only reading btRead <- subset(lsa, nest==1 & domain==\"reading\")  # \\donttest{ ### random intercept model with groups mod1 <- repLmer(datL = btRead, ID = \"idstud\", wgt = \"wgt\", L1wgt=\"L1wgt\", L2wgt=\"L2wgt\",         type = \"jk2\", PSU = \"jkzone\", repInd = \"jkrep\", imp = \"imp\",trend=\"year\",         group=\"country\", dependent=\"score\", formula.fixed = ~as.factor(sex)+mig,         formula.random=~1, clusters=\"idclass\") #> Logical variable 'mig' will be transformed into numeric. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #>  #> BIFIE.data.jack(data = \"datL\", wgt = \"wgt\", jktype = \"JK_TIMSS\",  #>     jkzone = \"jkzone\", jkrep = \"jkrep\", jkfac = NULL, fayfac = NULL,  #>     cdata = FALSE) #> MI data with 3 datasets || 92 replication weights with fayfac=1  || 3079 cases and 14 variables  #>   #> Imputation 1 | Group 1 |----------  #> Imputation 1 | Group 2 |----------  #> Imputation 1 | Group 3 |----------  #> Imputation 2 | Group 1 |----------  #> Imputation 2 | Group 2 |----------  #> Imputation 2 | Group 3 |----------  #> Imputation 3 | Group 1 |----------  #> Imputation 3 | Group 2 |----------  #> Imputation 3 | Group 3 |----------  #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #>  #> BIFIE.data.jack(data = \"datL\", wgt = \"wgt\", jktype = \"JK_TIMSS\",  #>     jkzone = \"jkzone\", jkrep = \"jkrep\", jkfac = NULL, fayfac = NULL,  #>     cdata = FALSE) #> MI data with 3 datasets || 73 replication weights with fayfac=1  || 2928 cases and 14 variables  #>   #> Imputation 1 | Group 1 |--------  #> Imputation 1 | Group 2 |--------  #> Imputation 1 | Group 3 |--------  #> Imputation 2 | Group 1 |--------  #> Imputation 2 | Group 2 |--------  #> Imputation 2 | Group 3 |--------  #> Imputation 3 | Group 1 |--------  #> Imputation 3 | Group 2 |--------  #> Imputation 3 | Group 3 |--------  #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. res1 <- report(mod1)  ### random slope without groups and without trend mod2 <- repLmer(datL = subset(btRead, country==\"countryA\" & year== 2010),         ID = \"idstud\", wgt = \"wgt\", L1wgt=\"L1wgt\", L2wgt=\"L2wgt\", type = \"jk2\",         PSU = \"jkzone\", repInd = \"jkrep\", imp = \"imp\", dependent=\"score\",         formula.fixed = ~as.factor(sex)*mig, formula.random=~mig, clusters=\"idclass\") #> Logical variable 'mig' will be transformed into numeric. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #>  #> BIFIE.data.jack(data = \"datL\", wgt = \"wgt\", jktype = \"JK_TIMSS\",  #>     jkzone = \"jkzone\", jkrep = \"jkrep\", jkfac = NULL, fayfac = NULL,  #>     cdata = FALSE) #> MI data with 3 datasets || 32 replication weights with fayfac=1  || 1034 cases and 14 variables  #>   #> Imputation 1 | Group 1 |---  #> Imputation 2 | Group 1 |---  #> Imputation 3 | Group 1 |---  #>  res2 <- report(mod2) # }"},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"Compute totals, means, adjusted means, mean differences, variances standard deviations standard errors random clustered complex samples. Variance estimation complex cluster designs based Jackknife (JK1, JK2) Balanced Repeated Replicates (BRR) procedure. Moreover, analyses can customized multiple nested imputed variables, applying combination rules Rubin (1987) imputed data Rubin (2003) nested imputed data. Conceptually, function combines replication methods methods multiple imputed data. Trend estimation usual large-scale assessments supported well. Technically, wrapper svymean svyvar functions survey package.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"","code":"repMean (datL, ID, wgt = NULL, type = c(\"none\", \"JK2\", \"JK1\", \"BRR\", \"Fay\"), PSU = NULL,          repInd = NULL, jkfac=NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,          group.splits = length(groups), group.differences.by = NULL,          cross.differences = FALSE, crossDiffSE = c(\"wec\", \"rep\",\"old\"),          adjust = NULL, useEffectLiteR = FALSE, nBoot = 100, group.delimiter = \"_\",          trend = NULL, linkErr = NULL, dependent, na.rm = FALSE, doCheck = TRUE,          engine = c(\"survey\", \"BIFIEsurvey\"), scale = 1, rscales = 1, mse=TRUE,          rho=NULL, hetero=TRUE, se_type = c(\"HC3\", \"HC0\", \"HC1\", \"HC2\", \"CR0\", \"CR2\"),          clusters = NULL, crossDiffSE.engine= c(\"lavaan\", \"lm\"),          stochasticGroupSizes = FALSE, verbose = TRUE, progress = TRUE, nCores=NULL)"},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"datL Data frame long format (.e. line represents one ID unit one imputation one nest) containing variables analysis. ID Variable name column number student identifier (ID) variable. ID variable must contain missing values. wgt Optional: Variable name column number weighting variable. weighting variable specified, cases equally weighted. type Defines replication method cluster replicates applied. Depending type, additional arguments must specified (e.g., PSU /repInd repWgt). PSU Variable name column number variable indicating primary sampling unit (PSU). jackknife procedure applied, PSU jackknife zone variable. NULL, cluster structure assumed standard errors computed according random sample. repInd Variable name column number variable indicating replicate ID. jackknife procedure, jackknife replicate variable. NULL, cluster structure assumed standard errors computed according random sample. jkfac applies engine = \"BIFIEsurvey\". Argument passed BIFIE.data.jack specifies factor multiplying jackknife replicate weights. repWgt Normally, replicate weights created repMean directly PSU repInd variables. Alternatively, replicate weights included data.frame, specify variable names column number repWgt argument. nest Optional: name column number nesting variable. applies nested multiple imputed data sets. imp Optional: name column number imputation variable. applies multiple imputed data sets. groups Optional: vector names column numbers one grouping variables. group.splits Optional: groups defined, group.splits optionally specifies whether analysis done also whole group overlying groups. See examples details. group.differences.Optional: Specifies variable group differences computed . corresponding variable must included groups statement. Exception: choose 'wholePop' want estimate 's group difference overall sample mean. See examples details. cross.differences Either list vectors, specifying pairs levels cross-level differences computed. Alternatively, TRUE, cross-level differences pairs levels computed. FALSE, cross-level differences computed. (see example 2a, 3, 4) crossDiffSE Method standard error estimation cross level differences, groups dependent. wec uses weighted effect coding, rep uses replication methods (bootstrap jackknife) estimate standard error total mean group-specific means. old account dependent groups treat groups independent . adjust Variable name column number variable(s) adjusted means computed. Non-numeric variables (factors) converted 0/1 dichotomous variables. useEffectLiteR Logical: use lavaan-wrapper EffectLiteR compute adjusted means? Alternatively, adjusted means computed applying simple linear regression model group, using variables adjust independent variables. Afterwards, coefficients weighted (weighted) means independent variables. Standard errors procedure received using delta method applying augmented variance-covariance matrix assumes zero covariances independent variable means regression coefficients. recommend set useEffectLiteR = TRUE replication methods applied. replication methods used (jackknife-1, jackknife-2, BRR), recommend set useEffectLiteR = FALSE, otherwise estimation slow. nBoot Without replicates (.e., completely random samples), rep method standard error estimation cross level differences needs bootstrap. nBoot therefore specifies number bootstrap samples. argument necessary, crossDiffSE = \"rep\" none replicate methods (JK1, JK2, BRR) applied. Otherwise, nBoot ignored. group.delimiter Character string separates group names output frame. trend Optional: name column number trend variable contains measurement time survey. Note: Levels grouping variables must equal 'sub populations' partitioned discrete trend variable. repMean computes differences pairwise contrasts defined trend variable levels. three measurement occasions, .e. 2010, 2015, 2020, contrasts (.e. trends) computed 2010 vs. 2015, 2010 vs. 2020, 2015 vs. 2020. linkErr Optional: Either name column number linking error variable. NULL, linking error 0 assumed trend estimation. Alternatively, linking errors may given data.frame following specifications: Two columns, named trendLevel1 trendLevel2 contain levels trend variable. contrasts values indicates trend meant. two measurement occasions, .e. 2010 2015, trendLevel1 2010, trendLevel2 2015. three measurement occasions, .e. 2010, 2015, 2020, additional lines necessary trendLevel1 2010, trendLevel2 2020, mark contrast 2010 2020, additional lines necessary trendLevel1 2015, trendLevel2 2020. column depVar must include name dependent variable. string must correspond name dependent variable data. column parameter indicates parameter linking error belongs . Column linkingError includes linking error value. Providing linking error data.frame necessary two measurement occasions. See example 3a details. dependent Variable name column number dependent variable. na.rm Logical: cases missing values dropped? doCheck Logical: Check data consistency analysis? TRUE groups insufficient data excluded analysis prevent subsequent functions crashing. engine package used estimation? scale scaling constant variance, details, see help page svrepdesign survey package rscales scaling constant variance, details, see help page svrepdesign survey package mse Logical: TRUE, compute variances based sum squares around point estimate, rather mean replicates. See help page svrepdesign survey package details. rho Shrinkage factor weights Fay's method. engine = \"survey\", argument passed rho argument svrepdesign function survey package. See corresponding help page details. engine = \"BIFIEsurvey\", argument passed fayfac argument BIFIE.data.jack function BIFIEsurvey package. See corresponding help page details. convenience, rho = NULL (default) engine = \"BIFIEsurvey\" type = \"JK1\", BIFIE.data.jack called jktype=\"JK_GROUP\" fayfac = rho, \\(\\rho = (N_{cluster} - 1) \\times N_{cluster}^{-1}\\) hetero Logical: Assume heteroscedastic variance weighted effect coding? se_type sort standard error sought cross level differences. applies crossDiffSE == \"wec\" hetero == TRUE crossDiffSE.engine == \"lm\". See help page lm_robust estimatr package details. clusters Optional: Variable name column number cluster variable. necessary weighted effecting coding performed using heteroscedastic variances. See help page lm_robust estimatr package details. crossDiffSE.engine Software implementation used estimating cross-level differences. Choices either \"lavaan\" (required stochasticGroupSites == \"TRUE\") R function lm. \"lavaan\" default. stochasticGroupSizes Logical: Assume stochastic group sizes using weighted effect coding cross-level differences? Note: date, crossDiffSE.engine = \"lavaan\" allows stochastic group sizes. Stochastic group sizes yet implemented replication method (jackknife, BRR). verbose Logical: Show analysis information console? progress Logical: Show progress bar console? nCores integer (default: NULL), number cores use parallel processing, engine = \"survey\". NULL, single core processing used.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"Function first creates replicate weights based PSU repInd variables (defined) according JK2 BRR procedure implemented WesVar. According multiple imputed data sets, workbook several analyses created. function afterwards serves wrapper svymean called svyby implemented ‘survey’ package. results several analyses pooled according Rubin's rule.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"list data frames long format. output can summarized using report function. first element list list either one (trend analyses) two (trend analyses) data frames least six columns . subpopulation denoted groups statement, parameter (.e., mean, variance, group differences) coefficient (.e., estimate corresponding standard error) corresponding value given. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 analysis without sampling weights conducted, ‘modus’ takes value ‘jk2.unweighted’. analysis without replicates sampling weights conducted, ‘modus’ takes value ‘weighted’. parameter Denotes parameter regression model corresponding value given . Amongst others, ‘parameter’ column takes values ‘mean’, ‘sd’, ‘var’ ‘meanGroupDiff’ group differences requested. coefficient Denotes coefficient corresponding value given . Takes values ‘est’ (estimate) ‘se’ (standard error estimate). value value parameter estimate corresponding group. groups specified, columns denoted group names added data frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"te Grotenhuis, M., Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, ., & Konig, R. (2017). size matters: advantages weighted effect coding observational studies. International Journal Public Health. 62, 163–167. Sachse, K. . & Haag, N. (2017). Standard errors national trends international large-scale assessments case cross-national differential item functioning. Applied Measurement Education, 30, (2), 102-116. http://dx.doi.org/10.1080/08957347.2017.1283315 Weirich, S., Hecht, M., Becker, B. et al. Comparing group means total mean random samples, surveys, large-scale assessments: tutorial software illustration. Behav Res (2021). https://doi.org/10.3758/s13428-021-01553-1","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replication methods (JK1, JK2 and BRR) for descriptive statistics. — repMean","text":"","code":"data(lsa)  ### Example 1: only means, SD and variances for each country ### We only consider domain 'reading' rd     <- lsa[which(lsa[,\"domain\"] == \"reading\"),]  ### We only consider the first \"nest\". rdN1   <- rd[which(rd[,\"nest\"] == 1),]  ### First, we only consider year 2010 rdN1y10<- rdN1[which(rdN1[,\"year\"] == 2010),]  ### mean estimation means1 <- repMean(datL = rdN1y10, ID=\"idstud\", wgt=\"wgt\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = \"country\", dependent = \"score\",           na.rm=FALSE, doCheck=TRUE, engine = \"BIFIEsurvey\") #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #>  #> BIFIE.data.jack(data = \"datL\", wgt = \"wgt\", jktype = \"JK_TIMSS\",  #>     jkzone = \"jkzone\", jkrep = \"jkrep\", jkfac = NULL, fayfac = NULL,  #>     cdata = FALSE) #> MI data with 3 datasets || 92 replication weights with fayfac=1  || 3079 cases and 10 variables  #> 'BIFIE.univar' for 'call = mean'. dependent = 'score'. group(s) = 'country'.  #>  ### reporting function: the function does not know which content domain is being considered, ### so the user may add new columns in the output using the 'add' argument res1   <- report(means1, add = list(domain = \"reading\"))  # \\donttest{ ### Example 1a: Additionally to example 1, we decide to estimate whether ### each country's mean differ significantly from the overall mean as well ### as from the individual means of the other contries means1a<- repMean(datL = rdN1y10, ID=\"idstud\", wgt=\"wgt\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = \"country\", group.splits = 0:1,           group.differences.by = \"country\", cross.differences = TRUE,           dependent = \"score\", na.rm=FALSE, doCheck=TRUE, hetero=FALSE) #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> Compute cross level differences using 'wec' method. Assume homoscedastic variances. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res1a  <- report(means1a, add = list(domain = \"reading\"))  ### See that the means of all countries significantly differ from the overall mean. print(res1a[intersect(which(res1a[,\"comparison\"] == \"crossDiff\"),       which(res1a[,\"parameter\"] == \"mean\")),], digits = 3) #>    parameter            modus depVar comparison                        group #> 4       mean JK2.mean__survey  score  crossDiff crossDiff (countryA - total) #> 10      mean JK2.mean__survey  score  crossDiff crossDiff (countryB - total) #> 17      mean JK2.mean__survey  score  crossDiff crossDiff (countryC - total) #>     domain                country     es   est     p   se #> 4  reading countryA.vs.wholeGroup -0.139 -11.1 0.000 2.95 #> 10 reading countryB.vs.wholeGroup -0.169 -14.1 0.001 4.43 #> 17 reading countryC.vs.wholeGroup  0.141  11.6 0.000 2.07  ### Example 2: Sex differences by country. Assume equally weighted cases by omitting ### 'wgt' argument. means2 <- repMean(datL = rdN1y10, ID=\"idstud\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,           group.differences.by=\"sex\", dependent = \"score\", na.rm=FALSE, doCheck=TRUE,           cross.differences =TRUE, crossDiffSE.engine= \"lm\") #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> Compute cross level differences using 'wec' method. Assume heteroscedastic variances. #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 32 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 60 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 40 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 91 replicate weights according to JK2 procedure. #>  #>    'wec' method: Assume equally weighted cases. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res2   <- report(means2,add = list(domain = \"reading\")) #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported.  ### Example 2a: Additionally to example 2, we decide to estimate whether ### each country's mean differ significantly from the overall mean. (Note: by default, ### such cross level differences are estimated using 'weighted effect coding'. Use the ### 'crossDiffSE' argument to choose alternative methods.) Moreover, we estimate whether ### each country's sex difference differ significantly from the sex difference in the ### whole population. means2a<- repMean(datL = rdN1y10, ID=\"idstud\", wgt=\"wgt\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = c(\"country\", \"sex\"), group.splits = 0:2,           group.differences.by=\"sex\", cross.differences = list(c(0,1), c(0,2)),           dependent = \"score\", na.rm=FALSE, doCheck=TRUE,           crossDiffSE.engine= \"lm\", clusters = \"idclass\") #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> Warning: Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res2a  <- report(means2a,add = list(domain = \"reading\")) #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported.  ### Third example: like example 2a, but using nested imputations of dependent variable, ### and additionally estimating trend: use 'rd' instead of 'rdN1y10' ### assume equally weighted cases by omitting 'wgt' argument ### ignoring jackknife by omitting 'type', 'PSU' and 'repInd' argument means3T<- repMean(datL = rd, ID=\"idstud\", imp=\"imp\", nest=\"nest\",           groups = c(\"country\", \"sex\"), group.splits = 0:2, group.differences.by=\"sex\",           cross.differences = list(c(0,1), c(0,2)), dependent = \"score\", na.rm=FALSE,           doCheck=TRUE, trend = \"year\", linkErr = \"leScore\",           crossDiffSE = \"wec\", crossDiffSE.engine= \"lavaan\") #>  #> Trend group: '2010' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Warning: Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. #>    'wec' method: Assume equally weighted cases. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. #>    'wec' method: Assume equally weighted cases. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. res3T  <- report(means3T, add = list(domain = \"reading\")) #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported.  ### Example 3a: like example 3, but providing linking errors in an additional data.frame ### This is optional for two measurement occasions but mandatory if the analysis contains ### more than two measurement occasions linkErr<- data.frame ( trendLevel1 = 2010, trendLevel2 = 2015,  depVar = \"score\",           parameter = \"mean\", unique(lsa[,c(\"domain\", \"leScore\")]),           stringsAsFactors = FALSE) colnames(linkErr) <- car::recode(colnames(linkErr), \"'leScore'='linkingError'\") ### note that the linking errors for the specified domain have to be chosen via ### subsetting means3a<- repMean(datL = rd, ID=\"idstud\", imp=\"imp\", nest=\"nest\",           groups = c(\"country\", \"sex\"),           group.splits = 0:2, group.differences.by=\"sex\",           cross.differences = list(c(0,1), c(0,2)),           dependent = \"score\", na.rm=FALSE, doCheck=TRUE, trend = \"year\",           linkErr = linkErr[which(linkErr[,\"domain\"] == \"reading\"),],           crossDiffSE = \"wec\", crossDiffSE.engine= \"lavaan\") #>  #> Trend group: '2010' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Warning: Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. #>    'wec' method: Assume equally weighted cases. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. #>    'wec' method: Assume equally weighted cases. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. res3a  <- report(means3a, add = list(domain = \"reading\")) #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. #> Warning: No linking errors for parameters 'Ncases', 'NcasesValid', 'sd', 'var'. Linking errors for these parameters will be defaulted to 0. #> Warning: Found 23 missing linking errors for dependent variable 'score' and parameter(s) 'sd'. Assume linking error of 0 for these cases.  ### Fourth example: using a loop do analyse 'reading' and 'listening' comprehension ### in one function call. Again with group and cross differences and trends, and ### trend differences ### we use weights but omit jackknife analysis by omitting 'type', 'PSU' and 'repInd' ### argument means4T<- by ( data = lsa, INDICES = lsa[,\"domain\"], FUN = function (sub.dat) {           repMean(datL = sub.dat, ID=\"idstud\", wgt=\"wgt\", imp=\"imp\", nest=\"nest\",                  groups = c(\"country\", \"sex\"), group.splits = 0:2,                  group.differences.by=\"sex\",                  cross.differences = list(c(0,1), c(0,2)), dependent = \"score\",                  na.rm=FALSE, doCheck=TRUE,                  trend = \"year\", linkErr = \"leScore\", crossDiffSE.engine= \"lm\") }) #>  #> Trend group: '2010' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Warning: Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. #>  #> Trend group: '2010' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 4 analyse(s) overall according to: 'group.splits = 0 1 2'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country                 <NA> #>                3               1               sex                  sex #>                4               2     country + sex                  sex #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Warning: Computation of cross level differences using 'wec' method is only possible for differences according to adjacent levels. Non-adjacent levels will be ignored. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #> Note: No linking error was defined. Linking error will be defaulted to '0'. ret4T  <- do.call(\"rbind\", lapply(names(means4T), FUN = function ( domain ) {           report(means4T[[domain]], add = list(domain = domain))})) #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported. #> Warning: Standard error correction for 'crossDiff_of_groupDiff' is currently not supported. #> Warning: Standard error correction for crossDifferences across multiple hierarchy levels is currently not supported.            ### Fifth example: compute adjusted means, also with trend estimation ### Note: all covariates must be numeric or 0/1 dichotomous rdN1[,\"mignum\"] <- as.numeric(rdN1[,\"mig\"]) rdN1[,\"sexnum\"] <- car::recode(rdN1[,\"sex\"], \"'male'=0; 'female'=1\", as.numeric=TRUE,                    as.factor=FALSE) means5 <- repMean(datL = rdN1, ID=\"idstud\", wgt=\"wgt\", type = \"JK2\", PSU = \"jkzone\",           repInd = \"jkrep\", imp=\"imp\", groups = \"country\",           adjust = c(\"sexnum\", \"ses\", \"mignum\"), useEffectLiteR = FALSE,           dependent = \"score\", na.rm=FALSE, doCheck=TRUE, trend = \"year\",           linkErr = \"leScore\") #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 73 replicate weights according to JK2 procedure. #>  res5   <- report(means5, add = list(domain = \"reading\")) #> Cannot find standard deviations in output. Skip computation of effect sizes.  if (FALSE) { # \\dontrun{ ############################################################################################ #    Example 6: R code for running the PISA 2015 science example to compare group means    # #                    with the total mean using weighted effect coding                      # ############################################################################################  # Warning: large PISA data set requires at least 16 GB free working memory (RAM):  ### define necessary directories (note: writing permissions required) folder <- tempdir()  ### download PISA 2015 zipped student questionnaire data (420 MB) to a folder with ### writing permissions download.file(url = \"https://webfs.oecd.org/pisa/PUF_SPSS_COMBINED_CMB_STU_QQQ.zip\",          destfile = file.path(folder, \"pisa2015.zip\"))  ### unzip PISA 2015 student questionnaire data (1.5 GB) to temporary folder zip::unzip(zipfile = file.path(folder, \"pisa2015.zip\"), files= \"CY6_MS_CMB_STU_QQQ.sav\",      exdir=folder)  ### read data pisa <- foreign::read.spss(file.path (folder, \"CY6_MS_CMB_STU_QQQ.sav\"),         to.data.frame=TRUE, use.value.labels = FALSE, use.missings = TRUE)  # dependent variables measure.vars <- paste0(\"PV\", 1:10, \"SCIE\")  ### choose desired variables and reshape into the long format #              'CNTSTUID' = individual student identifier #                   'CNT' = country identifier #                 'SENWT' = senate weight (assume a population of 5000 in each country) #              'W_FSTUWT' = final student weight #                  'OECD' = dummy variable indicating which country is part of the OECD #   'W_FSTURWT' (1 to 80) = balanced repeated replicate weights # 'PV1SCIE' to 'PV10SCIE' = 10 plausible values of (latent) science performance pisaLong <- reshape2::melt(pisa, id.vars = c(\"CNTSTUID\", \"CNT\", \"SENWT\", \"W_FSTUWT\",             \"OECD\", paste0(\"W_FSTURWT\", 1:80)),             measure.vars = measure.vars, value.name = \"value\", variable.name=\"imp\",             na.rm=TRUE)  ### choose OECD countries oecd <- pisaLong[which(pisaLong[,\"OECD\"] == 1),]  ### analyze data ### analysis takes approximately 30 minutes on an Intel i5-6500 machine with 32 GB RAM means   <- repMean( datL = oecd,         # data.frame in the long format     ID                   = \"CNTSTUID\",   # student identifier     dependent            = \"value\",      # the dependent variable in the data     groups               = \"CNT\",        # the grouping variable     wgt                  = \"SENWT\",      # (optional) weighting variable. We use senate                                          # weights (assume a population of 5000 in each                                          # country)     type                 = \"Fay\",        # type of replication method. Corresponding to                                          # the PISA sampling method, we use \"Fay\"     rho                  = 0.5,          # shrinkage factor for weights in Fay's method     scale                = NULL,         # scaling constant for variance, set to NULL                                          # according to PISA's sampling method     rscales              = NULL,         # scaling constant for variance, set to NULL                                          # according to PISA's sampling method     repWgt               = paste0(\"W_FSTURWT\", 1:80), # the replicate weights,                                                       # provided by the OECD     imp                  = \"imp\",        # the imputation variable     mse                  = FALSE,        # if TRUE, compute variances based on sum of                                          # squares around the point estimate, rather                                          # than the mean of the replicates.     group.splits         = 0:1,          # defining the 'levels' for which means should                                          # be computed. 0:1 implies that means for the                                          # whole sample (level 0) as well as for groups                                          # (level 1) are computed     cross.differences    = TRUE,         # defines whether (and which) cross level mean                                          # differences should be computed. TRUE means                                          # that all cross level mean differences are                                          # computed     crossDiffSE          = \"wec\",        # method for standard errors of mean                                          # differences     crossDiffSE.engine   = \"lm\",         # software implementation for standard                                          # errors of mean differences     hetero               = TRUE,         # assume heteroscedastic group variances     stochasticGroupSizes = FALSE         # assume fixed group sizes                    )  ### call a reporting function to generate user-friendly output results <- report(means, exclude = c(\"Ncases\", \"NcasesValid\", \"var\", \"sd\")) } # }# }"},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"Compute quantiles standard errors complex cluster designs multiple imputed variables (e.g. plausible values) based Jackknife (JK1, JK2) balanced repeated replicates (BRR) procedure. Conceptually, function combines replication methods methods multiple imputed data. Technically, wrapper svyquantile() function survey package.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"","code":"repQuantile(datL, ID, wgt = NULL, type = c(\"none\", \"JK2\", \"JK1\", \"BRR\", \"Fay\"),             PSU = NULL, repInd = NULL, repWgt = NULL, nest=NULL, imp=NULL,             groups = NULL, group.splits = length(groups), cross.differences = FALSE,             group.delimiter = \"_\", trend = NULL, linkErr = NULL, dependent,             probs = c(0.25, 0.50, 0.75),  na.rm = FALSE, nBoot = NULL,             bootMethod = c(\"wSampling\",\"wQuantiles\") , doCheck = TRUE,             scale = 1, rscales = 1, mse=TRUE,             rho=NULL, verbose = TRUE, progress = TRUE)"},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"datL Data frame long format (.e. line represents one ID unit one imputation one nest) containing variables analysis. ID Variable name column number student identifier (ID) variable. ID variable must contain missing values. wgt Optional: Variable name column number weighting variable. weighting variable specified, cases equally weighted. type Defines replication method cluster replicates applied. Depending type, additional arguments must specified (e.g., PSU /repInd repWgt). PSU Variable name column number variable indicating primary sampling unit (PSU). jackknife procedure applied, PSU jackknife zone variable. NULL, cluster structure assumed standard errors computed according random sample. repInd Variable name column number variable indicating replicate ID. jackknife procedure, jackknife replicate variable. NULL, cluster structure assumed standard errors computed according random sample. repWgt Normally, replicate weights created repQuantile directly PSU repInd variables. Alternatively, replicate weights included data.frame, specify variable names column number repWgt argument. nest Optional: name column number nesting variable. applies nested multiple imputed data sets. imp Optional: name column number imputation variable. applies multiple imputed data sets. groups Optional: vector names column numbers one grouping variables. group.splits Optional: groups defined, group.splits optionally specifies whether analysis done also whole group overlying groups. See examples details. cross.differences Either list vectors, specifying pairs levels cross-level differences computed. Alternatively, TRUE, cross-level differences pairs levels computed. FALSE, cross-level differences computed. (see examples 2a, 3, 4 help file repMean function) group.delimiter Character string separates group names output frame. trend Optional: name column number trend variable contains measurement time survey. Note: Levels grouping variables must equal 'sub populations' partitioned discrete trend variable. repQuantile computes differences pairwise contrasts defined trend variable levels. three measurement occasions, .e. 2010, 2015, 2020, contrasts (.e. trends) computed 2010 vs. 2015, 2010 vs. 2020, 2015 vs. 2020. linkErr Optional: Either name column number linking error variable. NULL, linking error 0 assumed trend estimation. Alternatively, linking errors may given data.frame following specifications: Two columns, named trendLevel1 trendLevel2 contain levels trend variable. contrasts values indicates trend meant. two measurement occasions, .e. 2010 2015, trendLevel1 2010, trendLevel2 2015. three measurement occasions, .e. 2010, 2015, 2020, additional lines necessary trendLevel1 2010, trendLevel2 2020, mark contrast 2010 2020, additional lines necessary trendLevel1 2015, trendLevel2 2020. column depVar must include name dependent variable. string must correspond name dependent variable data. column parameter indicates parameter linking error belongs . Column linkingError includes linking error value. Providing linking error data.frame necessary two measurement occasions. dependent Variable name column number dependent variable. probs Numeric vector probabilities compute quantiles. na.rm Logical: cases missing values dropped? nBoot Optional: Without replicates, standard error computed weighted sample. Alternatively, standard errors may computed using boot package. nBoot therefore specifies number bootstrap samples. specified, standard errors given. analyses containing replicates samples without specifying person weights, nBoot ignored. bootMethod Optional: standard error computed bootstrap, two possible methods may applied. wSampling requests function draw nBoot weighted bootstrap samples unweighted quantiles computed. wQuantiles requests function draw nBoot unweighted bootstrap samples weighted quantiles computed. doCheck Logical: Check data consistency analysis? TRUE groups insufficient data excluded analysis prevent subsequent functions crashing. scale scaling constant variance, details, see help page svrepdesign survey package rscales scaling constant variance, details, see help page svrepdesign survey package mse Logical: TRUE, compute variances based sum squares around point estimate, rather mean replicates. See help page svrepdesign survey package details. rho Shrinkage factor weights Fay's method. See help page svrepdesign survey package details. verbose Logical: Show analysis information console? progress Logical: Show progress bar console?","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"Function first creates replicate weights based PSU repInd variables according JK2 BRR procedure implemented WesVar. According multiple imputed data sets, workbook several analyses created. function afterwards serves wrapper svyquantile called svyby implemented survey package. results several analyses pooled according Rubins rule, adapted nested imputations dependent argument implies nested structure.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"list data frames long format. output can summarized using report function. first element list list either one (trend analyses) two (trend analyses) data frames least six columns . subpopulation denoted groups statement, dependent variable, parameter (.e., values corresponding categories dependent variable) coefficient (.e., estimate corresponding standard error) corresponding value given. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 analysis without sampling weights conducted, ‘modus’ takes value ‘jk2.unweighted’. analysis without replicates sampling weights conducted, ‘modus’ takes value ‘weighted’. parameter Denotes parameter regression model corresponding value given . frequency tables, value category dependent variable relative frequency given . coefficient Denotes coefficient corresponding value given . Takes values ‘est’ (estimate) ‘se’ (standard error estimate). value value parameter, .e. relative frequency standard error. groups specified, columns denoted group names added data frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repQuantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation. — repQuantile","text":"","code":"# \\donttest{ data(lsa) ### Example 1: only means, SD and variances for each country ### We only consider domain 'reading' rd     <- lsa[which(lsa[,\"domain\"] == \"reading\"),]  ### We only consider the first \"nest\". rdN1   <- rd[which(rd[,\"nest\"] == 1),]  ### First, we only consider year 2010 rdN1y10<- rdN1[which(rdN1[,\"year\"] == 2010),]  ### First example: Computes percentile in a nested data structure for reading  ### scores conditionally on country and for the whole group  perzent   <- repQuantile(datL = rd, ID = \"idstud\", wgt = \"wgt\", type = \"JK2\",              PSU = \"jkzone\", repInd = \"jkrep\", imp = \"imp\", nest=\"nest\",              groups = \"country\", group.splits = c(0:1), dependent = \"score\",               probs = seq(0.1,0.9,0.2) ) #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                     NA #>                2               1           country                   NA #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 98 replicate weights according to JK2 procedure. #>  res       <- report(perzent, add = list(domain = \"reading\"))  ### Second example: Computes percentile for reading scores conditionally on country, ### use 100 bootstrap samples, assume no nested structure  perzent2  <- repQuantile(datL = rdN1y10, ID = \"idstud\", wgt = \"wgt\",              imp = \"imp\", groups = \"country\", dependent = \"score\",              probs = seq(0.1,0.9,0.2), nBoot = 100 ) #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #>  res2      <- report(perzent, add = list(domain = \"reading\")) # }"},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":null,"dir":"Reference","previous_headings":"","what":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"Compute frequency tables categorical variables (e.g. factors: dichotomous polytomous) complex cluster designs. Estimation standard errors optionally takes clustered structure multiple imputed variables account. date, Jackknife-1 (JK1), Jackknife-2 (JK2) Balanced repeated replicate (BRR) methods implemented account clustered designs. Procedures Rubin (1987) Rubin (2003) implemented account multiple imputed data nested imputed data, necessary. Conceptually, function combines replication imputation methods. Technically, wrapper svymean function survey package.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"","code":"repTable(datL, ID, wgt = NULL, type = c(\"none\", \"JK2\", \"JK1\", \"BRR\", \"Fay\"), PSU = NULL,           repInd = NULL, jkfac=NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,           group.splits = length(groups), group.differences.by = NULL,           cross.differences = FALSE, crossDiffSE = c(\"wec\", \"rep\",\"old\"),           nBoot = 100, chiSquare = FALSE, correct = TRUE, group.delimiter = \"_\",           trend = NULL, linkErr = NULL, dependent, separate.missing.indicator = FALSE,           na.rm=FALSE, expected.values = NULL, doCheck = TRUE, forceTable = FALSE,           engine = c(\"survey\", \"BIFIEsurvey\"), scale = 1, rscales = 1, mse=TRUE,           rho=NULL, verbose = TRUE, progress = TRUE, nCores=NULL )"},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"datL Data frame long format (.e. line represents one ID unit one imputation one nest) containing variables analysis. ID Variable name column number student identifier (ID) variable. ID variable must contain missing values. wgt Optional: Variable name column number weighting variable. weighting variable specified, cases equally weighted. type Defines replication method cluster replicates applied. Depending type, additional arguments must specified (e.g., PSU /repInd repWgt). PSU Variable name column number variable indicating primary sampling unit (PSU). jackknife procedure applied, PSU jackknife zone variable. NULL, cluster structure assumed standard errors computed according random sample. repInd Variable name column number variable indicating replicate ID. jackknife procedure, jackknife replicate variable. NULL, cluster structure assumed standard errors computed according random sample. jkfac applies engine = \"BIFIEsurvey\". Argument passed BIFIE.data.jack specifies factor multiplying jackknife replicate weights. repWgt Normally, replicate weights created repTable directly PSU repInd variables. Alternatively, replicate weights included data.frame, specify variable names column number repWgt argument. nest Optional: name column number nesting variable. applies nested multiple imputed data sets. imp Optional: name column number imputation variable. applies multiple imputed data sets. groups Optional: vector names column numbers one grouping variables. group.splits Optional: groups defined, group.splits optionally specifies whether analysis done also whole group overlying groups. See examples details. group.differences.Optional: Specifies one grouping variable chi-square test applied. corresponding variable must included groups statement. specified, distribution dependent variable compared groups. See examples details. cross.differences Either list vectors, specifying pairs levels cross-level differences computed. Alternatively, TRUE, cross-level differences pairs levels computed. FALSE, cross-level differences computed. (see examples 2a, 3, 4 help file repMean function) crossDiffSE Method standard error estimation cross level differences, groups dependent. wec uses weighted effect coding, rep uses replication methods (bootstrap jackknife) estimate standard error total mean group-specific means. old account dependent groups treat groups independent . nBoot Without replicates (.e., completely random samples), rep method standard error estimation cross level differences needs bootstrap. nBoot therefore specifies number bootstrap samples. argument necessary, crossDiffSE = \"rep\" none replicate methods (JK1, JK2, BRR) applied. Otherwise, nBoot ignored. chiSquare Logical. Applies group.differences.specified. Defines whether group differences represented chi square test (mean) differences group's relative frequency. Note: date, chi square test available engine = \"BIFIEsurvey\". correct Logical. Applies 'group.differences.' requested without cluster replicates. logical indicating whether apply continuity correction computing test statistic 2 2 tables. See help page 'chisq.test' details. group.delimiter Character string separates group names output frame. trend Optional: name column number trend variable contains measurement time survey. Note: Levels grouping variables must equal 'sub populations' partitioned discrete trend variable. repTable computes differences pairwise contrasts defined trend variable levels. three measurement occasions, .e. 2010, 2015, 2020, contrasts (.e. trends) computed 2010 vs. 2015, 2010 vs. 2020, 2015 vs. 2020. linkErr Optional: Either name column number linking error variable. NULL, linking error 0 assumed trend estimation. Alternatively, linking errors may given data.frame following specifications: Two columns, named trendLevel1 trendLevel2 contain levels trend variable. contrasts values indicates trend meant. two measurement occasions, .e. 2010 2015, trendLevel1 2010, trendLevel2 2015. three measurement occasions, .e. 2010, 2015, 2020, additional lines necessary trendLevel1 2010, trendLevel2 2020, mark contrast 2010 2020, additional lines necessary trendLevel1 2015, trendLevel2 2020. column depVar must include name dependent variable. string must correspond name dependent variable data. column parameter indicates parameter linking error belongs . Column linkingError includes linking error value. Providing linking error data.frame necessary two measurement occasions. See fourth example details. dependent Variable name column number dependent variable. separate.missing.indicator Logical. frequencies missings dependent variable integrated? Note: useful missing occur NA. dependent variable coded character, example 'male', 'female', 'missing', separate missing indicator necessary. na.rm Logical: cases missing values dropped? expected.values Optional. vector values expected dependent variable. Recommend left argument empty. doCheck Logical: Check data consistency analysis? TRUE groups insufficient data excluded analysis prevent subsequent functions crashing. forceTable Logical: Function decides internally whether table mean function survey called. mean function called, polytomous dependent variable converted dichotomous indicator variables. mean called, group differences category polytomous dependent variable can computed. table called, chi square statistic may computed. argument allows force function either call mean table. engine package used estimation? scale scaling constant variance, details, see help page svrepdesign survey package rscales scaling constant variance, details, see help page svrepdesign survey package mse Logical: TRUE, compute variances based sum squares around point estimate, rather mean replicates. See help page svrepdesign survey package details. rho Shrinkage factor weights Fay's method. engine = \"survey\", argument passed rho argument svrepdesign function survey package. See corresponding help page details. engine = \"BIFIEsurvey\", argument passed fayfac argument BIFIE.data.jack function BIFIEsurvey package. See corresponding help page details. convenience, rho = NULL (default) engine = \"BIFIEsurvey\" type = \"JK1\", BIFIE.data.jack called jktype=\"JK_GROUP\" fayfac = rho, \\(\\rho = (N_{cluster} - 1) \\times N_{cluster}^{-1}\\) verbose Logical: Show analysis information console? progress Logical: Show progress bar console? nCores integer (default: NULL), number cores use parallel processing, engine = \"survey\". NULL, single core processing used.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"Function first creates replicate weights based PSU repInd variables according JK2 procedure implemented WesVar. According multiple imputed data sets, workbook several analyses created. function afterwards serves wrapper svymean called svyby implemented survey package. Relative frequencies categories dependent variable computed means dichotomous indicators (e.g. dummy variables) category. results several analyses pooled according Rubin's rule, adapted nested imputations dependent argument implies nested structure.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"list data frames long format. output can summarized using report function. first element list list either one (trend analyses) two (trend analyses) data frames least six columns . subpopulation denoted groups statement, dependent variable, parameter (.e., values corresponding categories dependent variable) coefficient (.e., estimate corresponding standard error) corresponding value given. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 analysis without sampling weights conducted, ‘modus’ takes value ‘jk2.unweighted’. analysis without replicates sampling weights conducted, ‘modus’ takes value ‘weighted’. parameter Denotes parameter regression model corresponding value given . frequency tables, value category dependent variable relative frequency given . coefficient Denotes coefficient corresponding value given . Takes values ‘est’ (estimate) ‘se’ (standard error estimate). value value parameter, .e. relative frequency standard error. groups specified, columns denoted group names added data frame.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"Rubin, D.B. (2003): Nested multiple imputation NMES   via partially incompatible MCMC.   Statistica Neerlandica 57, 1, 3–18.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/repTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"JK1, JK2 and BRR for frequency tables and trend estimation. — repTable","text":"","code":"data(lsa)  ### Example 1: only means, SD and variances for each country ### subsetting: We only consider domain 'reading' rd     <- lsa[which(lsa[,\"domain\"] == \"reading\"),]  ### We only consider the first \"nest\". rdN1   <- rd[which(rd[,\"nest\"] == 1),]  ### First, we only consider year 2010 rdN1y10<- rdN1[which(rdN1[,\"year\"] == 2010),]  ### First example: Computes frequencies of polytomous competence levels (1, 2, 3, 4, 5) ### conditionally on country, using a chi-square test to decide whether the distribution ### varies between countries (it's an overall test, i.e. with three groups, df1=8). freq.tab1 <- repTable(datL = rdN1y10, ID = \"idstud\", wgt = \"wgt\", imp=\"imp\",              type = \"JK2\", PSU = \"jkzone\", repInd = \"jkrep\", groups = \"country\",              group.differences.by = \"country\", dependent = \"comp\", chiSquare = TRUE) #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res1      <- report(freq.tab1, add = list ( domain = \"reading\" )) #> Chi sqare test results cannot be transferred to old report() structure and will be ignored. Please use report2() instead.  # \\donttest{ ### Second example: Computes frequencies of polytomous competence levels (1, 2, 3, 4, 5) ### conditionally on country. Now we test whether the frequency of each single category ### differs between pairs of countries (it's not an overall test ... repTable now ### calls repMean internally, using dummy variables) freq.tab2 <- repTable(datL = rdN1y10, ID = \"idstud\", wgt = \"wgt\", imp=\"imp\",              type = \"JK2\", PSU = \"jkzone\", repInd = \"jkrep\", groups = \"country\",              group.differences.by = \"country\", dependent = \"comp\", chiSquare = FALSE) #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  #> 1 analyse(s) overall according to: 'group.splits = 1'. #> Assume unnested structure with 3 imputations. #> Create 92 replicate weights according to JK2 procedure. #>  res2      <- report(freq.tab2, add = list ( domain = \"reading\" ))  ### Third example: trend estimation and nested imputation and 'by' loop ### (to date, only crossDiffSE = \"old\" works) freq.tab3 <- by ( data = lsa, INDICES = lsa[,\"domain\"], FUN = function (subdat) {              repTable(datL = subdat, ID = \"idstud\", wgt = \"wgt\", imp=\"imp\",                  nest = \"nest\", type = \"JK2\", PSU = \"jkzone\", repInd = \"jkrep\",                  groups = \"country\", group.differences.by = \"country\",                  group.splits = 0:1, cross.differences = TRUE, crossDiffSE = \"old\",                  dependent = \"comp\", chiSquare = FALSE, trend = \"year\",                  linkErr = \"leComp\") }) #> To date, only method 'old' is applicable for cross level differences in frequency tables. #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #> To date, only method 'old' is applicable for cross level differences in frequency tables. #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 92 replicate weights according to JK2 procedure. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #> Create 73 replicate weights according to JK2 procedure. #>  res3      <- do.call(\"rbind\", lapply(names(freq.tab3), FUN = function (domain) {              report(freq.tab3[[domain]], add = list ( domain = domain )) })) #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryA'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryB'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryC'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryA'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryB'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryC'. #> Warning: Found 7 missing linking errors for dependent variable 'comp' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryA'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryB'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryC'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryA'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryB'. #> Warning: No standard error for parameter 'NcasesValid'. Cannot compute standard errors and p value for cross-level difference between 'wholeGroup' and 'countryC'. #> Warning: Found 7 missing linking errors for dependent variable 'comp' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases.               ### Fourth example: similar to example 3. trend estimation using a linking ### error data.frame linkErrs  <- data.frame ( trendLevel1 = 2010, trendLevel2 = 2015,  depVar = \"comp\",              unique(lsa[,c(\"domain\", \"comp\", \"leComp\")]), stringsAsFactors = FALSE) colnames(linkErrs) <- car::recode(colnames(linkErrs),                       \"'comp'='parameter'; 'leComp'='linkingError'\") freq.tab4 <- by ( data = lsa, INDICES = lsa[,\"domain\"], FUN = function (subdat) {              repTable(datL = subdat, ID = \"idstud\", wgt = \"wgt\", type=\"none\",                  imp=\"imp\", nest = \"nest\", groups = \"country\",                  group.differences.by = \"country\", group.splits = 0:1,                  cross.differences = FALSE, dependent = \"comp\", chiSquare = FALSE,                  trend = \"year\",                  linkErr = linkErrs[which(linkErrs[,\"domain\"] == subdat[1,\"domain\"]),])              }) #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2010' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  #>  #> Trend group: '2015' #> 2 analyse(s) overall according to: 'group.splits = 0 1'. #>   #>  analysis.number hierarchy.level groups.divided.by group.differences.by #>                1               0                                   <NA> #>                2               1           country              country #>  #> Assume nested structure with 2 nests and 3 imputations in each nest. This will result in 2 x 3 = 6 imputation replicates. #>  res4      <- do.call(\"rbind\", lapply(names(freq.tab4), FUN = function (domain) {              report(freq.tab4[[domain]], add = list ( domain = domain ))  })) #> Warning: No linking errors for parameters 'Ncases', 'NcasesValid'. Linking errors for these parameters will be defaulted to 0. #> Warning: Found 4 missing linking errors for dependent variable 'comp' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases. #> Warning: No linking errors for parameters 'Ncases', 'NcasesValid'. Linking errors for these parameters will be defaulted to 0. #> Warning: Found 4 missing linking errors for dependent variable 'comp' and parameter(s) 'NcasesValid'. Assume linking error of 0 for these cases.  ### Fifth example: minimal example for three measurement occasions ### borrow data from the eatGADS package trenddat1 <- system.file(\"extdata\", \"trend_gads_2010.db\", package = \"eatGADS\") trenddat2 <- system.file(\"extdata\", \"trend_gads_2015.db\", package = \"eatGADS\") trenddat3 <- system.file(\"extdata\", \"trend_gads_2020.db\", package = \"eatGADS\") trenddat  <- eatGADS::getTrendGADS(filePaths = c(trenddat1, trenddat2, trenddat3),              years = c(2010, 2015, 2020), fast=FALSE) #>  -----  Loading GADS 2010 -----  #>  -----  Loading GADS 2015 -----  #>  -----  Loading GADS 2020 -----  dat       <- eatGADS::extractData(trenddat) ### use template linking Error Object load(system.file(\"extdata\", \"linking_error.rda\", package = \"eatRep\")) ### check consistency of data and linking error object check1 <- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr) #> The following variables have linking errors but are not variables in data base 1: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 2: 'value', 'valueTransfBista' #> The following variables have linking errors but are not variables in data base 3: 'value', 'valueTransfBista' ### Analysis for reading comprehension freq.tab5 <- repTable(datL = dat[which(dat[,\"dimension\"] == \"reading\"),],              ID = \"idstud\", type=\"none\", imp=\"imp\", dependent = \"traitLevel\",              chiSquare = FALSE, trend = \"year\",              linkErr = lErr[which(lErr[,\"domain\"] == \"reading\"),]) #> 'idVar' is unique per row in 'GADSdat' and checking for uniqueness is obsolete. #> 'idVar' is unique per row in 'GADSdat' and checking for uniqueness is obsolete. #>  #> Trend group: '2010' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #>  #>  #> Trend group: '2015' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #>  #>  #> Trend group: '2020' #> 1 analyse(s) overall according to: 'group.splits = 0'. #> Assume unnested structure with 3 imputations. #>  res5      <- report(freq.tab5, add = list ( domain = \"reading\" )) #> Warning: No linking errors for parameters 'Ncases'. Linking errors for these parameters will be defaulted to 0. #>  #>    Following 3 units in trend group '2010' without counterpart in trend group '2020'. #>  #>                  group     depVar comparison parameter coefficient     value #>          10 wholeGroup traitLevel       none         4         est 0.1333333 #>          11 wholeGroup traitLevel       none         4          se 0.1305260 #>          12 wholeGroup traitLevel       none         4           p 0.3070139 #>  #>    No '2010.vs.2020' trends will be computed. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'y' not included in data set 'x'. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'x' not included in data set 'y'. #> 1 of 3 unit(s) of merging variable 'coefficient' from data set 'y' not included in data set 'x'. #> 12 of 24 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'y' not included in data set 'x'. #> 2 of 14 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'x' not included in data set 'y'. #>  #>    Following 3 units in trend group '2015' without counterpart in trend group '2020'. #>  #>                  group     depVar comparison parameter coefficient     value #>          10 wholeGroup traitLevel       none         4         est 0.3333333 #>          11 wholeGroup traitLevel       none         4          se 0.1699673 #>          12 wholeGroup traitLevel       none         4           p 0.0498602 #>  #>    No '2015.vs.2020' trends will be computed. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'y' not included in data set 'x'. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'x' not included in data set 'y'. #> 1 of 3 unit(s) of merging variable 'coefficient' from data set 'y' not included in data set 'x'. #> 12 of 24 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'y' not included in data set 'x'. #> 2 of 14 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'x' not included in data set 'y'. res5A     <- report2(freq.tab5, add = list ( domain = \"reading\" )) #> Warning: No linking errors for parameters 'Ncases'. Linking errors for these parameters will be defaulted to 0. #>  #>    Following 3 units in trend group '2010' without counterpart in trend group '2020'. #>  #>                  group     depVar comparison parameter coefficient     value #>          10 wholeGroup traitLevel       none         4         est 0.1333333 #>          11 wholeGroup traitLevel       none         4          se 0.1305260 #>          12 wholeGroup traitLevel       none         4           p 0.3070139 #>  #>    No '2010.vs.2020' trends will be computed. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'y' not included in data set 'x'. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'x' not included in data set 'y'. #> 1 of 3 unit(s) of merging variable 'coefficient' from data set 'y' not included in data set 'x'. #> 12 of 24 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'y' not included in data set 'x'. #> 2 of 14 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'x' not included in data set 'y'. #>  #>    Following 3 units in trend group '2015' without counterpart in trend group '2020'. #>  #>                  group     depVar comparison parameter coefficient     value #>          10 wholeGroup traitLevel       none         4         est 0.3333333 #>          11 wholeGroup traitLevel       none         4          se 0.1699673 #>          12 wholeGroup traitLevel       none         4           p 0.0498602 #>  #>    No '2015.vs.2020' trends will be computed. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'y' not included in data set 'x'. #> 1 of 4 unit(s) of merging variable 'parameter' from data set 'x' not included in data set 'y'. #> 1 of 3 unit(s) of merging variable 'coefficient' from data set 'y' not included in data set 'x'. #> 12 of 24 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'y' not included in data set 'x'. #> 2 of 14 unit(s) of merging variable combination 'comparison'+'parameter'+'coefficient'+'year' from data set 'x' not included in data set 'y'. # }"},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":null,"dir":"Reference","previous_headings":"","what":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"Summarizes output four main functions repMean, repTable, repQuantile, repGlm, provides single data.frame results.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"","code":"report(repFunOut, trendDiffs = deprecated(), add=list(),        exclude = c(\"NcasesValid\", \"var\"),        printGlm = FALSE, round = TRUE, digits = 3, printDeviance = FALSE,        printSE_correction = FALSE) report2(repFunOut, add=list(), exclude = c(\"NcasesValid\", \"var\"), printGlm = FALSE,        round = TRUE, digits = 3, printDeviance = FALSE, printSE_correction = FALSE)"},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"repFunOut output one four eatRep-functions. trendDiffs deprecated. earlier versions package, argument used   determine differences trends. differences trends equivalent trend   differences (matter whether group cross-level differences), argument   deprecated. user specifies group cross-level difference along trends,   trends differences computed well. add Optional: additional columns output. See examples jk2-functions exclude parameters excluded reporting? printGlm relevant repGlm: print summary console? round Logical: results rounded limited number digits? digits many digits used rounding? printDeviance relevant repGlm   identical function used link function, printGlm TRUE.   deviance information printed additionally? Note: print deviance information,   argument poolMethod repGlm function must set   \"scalar\". printSE_correction Logical: Print differences original SEs cross   differences (method \"old\") SEs obtained \"wec\" \"rep\" method.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"report report2 differ output returned. output report2 optimized processing, .e. drawing plots means eatPlot package. report, output data frame least nine columns. group Denotes group analysis belongs . groups specified /analysis whole sample requested, value ‘group’ ‘wholeGroup’. depVar Denotes name dependent variable analysis. modus Denotes mode analysis. example, JK2 regression analysis conducted, ‘modus’ takes value ‘JK2.glm’. mean analysis without replicates conducted, ‘modus’ takes value ‘CONV.mean’. comparison Denotes whether group mean comparisons cross-level comparisons conducted. Without comparisons, ‘comparison’ takes value ‘NA’ parameter Denotes parameter corresponding analysis. regression analysis applied, regression parameter given. Amongst others, ‘parameter’ column takes values ‘(Intercept)’ ‘gendermale’ ‘gender’ independent variable, instance. mean analysis applied, ‘parameter’ column takes values ‘mean’, ‘sd’, ‘var’, ‘Nvalid’. See examples repMean,repTable, repQuantile, repGlm details. depVar Denotes name dependent variable (repGlm called ) est Denotes estimate corresponding analysis. se Denotes standard error corresponding estimate. p Denotes p value estimate. report2, output list four data.frames. first data.frame plain summarizes results human-readable form. data.frames 2 4 (comparisons, group, estimate) redundant plain contain results technical presentation suitable processing eatPlot. plain complete results human-readable form. comparison allocation table indicates comparison (group comparison cross-level comparison) relates groups. group table assigns ID analysis unit. makes easier later read output comparison relates groups. simplifies assignment, especially comparing comparisons (.e., cross-level differences group differences). estimate results analyses, assigned IDs.","code":""},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"Benjamin Becker, Sebastian Weirich","code":""},{"path":"https://weirichs.github.io/eatRep/reference/report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reporting functions for repMean, repTable, repQuantile, and repGlm — report","text":"","code":"### see examples of the eatRep main functions."},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0150","dir":"Changelog","previous_headings":"","what":"eatRep 0.15.0","title":"eatRep 0.15.0","text":"multicore computation supported analyses using survey package computation group differences using ‘group.differences.’ now also works adjusted means weighted analyses, eatRep functions now remove zero weight cases prior analyses avoid counting determining sample size eatRep functions now issue informative alerts missings occur dependent/independent jackknife variables. Missing occurrences concerned crucial caught error message enhanced warning messages number nests/imputations differ grouping variables enhanced warning messages number jkrep units differ nests/imputations bugfix cross-level differences group differences computation bugfix levels grouping variables contain leading /trailing spaces new function report2 summarizes output four main functions little tidier provides interface eatPlot. old reporting function report() deprecated new function pool.R2 computes pooled R^2 multiple imputed nested multiple imputed regression analyses according Harel (2009)","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0147","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.7","title":"eatRep 0.14.7","text":"CRAN release: 2023-03-26 exemplary variable labels stored attributed add ‘jkfac’ argument functions call BIFIEsurvey functions trend analyses (warning messages) now possible levels grouping variables differ assessment cycles bug fix internally used function checks linking error object consistency bug fix repLmer weights defined reporting function slightly simplified (.e., remove additional target formats)","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0146","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.6","title":"eatRep 0.14.6","text":"CRAN release: 2022-11-18 add function repLmer() replication methods linear multilevel models (wrapper BIFIEsurvey::BIFIE.twolevelreg()) bug fix internally used check function whether levels grouping variable(s) equal across assessment cycles (trend groups) bug fix singularity treatment repGlm() bug fix repQuantile() add Ns (sample size) output repTable() function add tests repQuantile() repLmer()","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0145","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.5","title":"eatRep 0.14.5","text":"CRAN release: 2022-07-08 compatibility lavaan version 0.6-12","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0144","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.4","title":"eatRep 0.14.4","text":"CRAN release: 2022-06-29 bug fix computation adjusted weighted means enhance performance recursive calls (e.g., trend estimation)","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0143","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.3","title":"eatRep 0.14.3","text":"CRAN release: 2022-05-14 add alternative output formats reporting function (argument target) bug fix standard error computation trend estimates bug fix repQuantile using 0% 100% percentil enhance performance using BIFIEsurvey wrapper","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0140","dir":"Changelog","previous_headings":"","what":"eatRep 0.14.0","title":"eatRep 0.14.0","text":"CRAN release: 2022-02-01 sorting parameters determination coefficient enhanced reporting function repGlm() add function checkLEs checks consistency linking errors data stem eatGADS data base trend estimation broadened two measurement occasions add class identifier exemplary data","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0137","dir":"Changelog","previous_headings":"","what":"eatRep 0.13.7","title":"eatRep 0.13.7","text":"CRAN release: 2021-10-28 add CR0 CR2 methods weighted effect coding heterogeneous variances repMean() repGlm(), including cluster argument add class ID variable example data set bug fix: fixed inadequate column definition reporting function repQuantile() adapt repQuantile function rewritten function svyquantile survey package slightly revised vignette","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0136","dir":"Changelog","previous_headings":"","what":"eatRep 0.13.6","title":"eatRep 0.13.6","text":"CRAN release: 2021-08-10 add asterisks significance console output reporting function repGlm() bug fix: fixed inadvertent warning message function group checks bug fix: call svyby return.replicates = FALSE quantile function","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0135","dir":"Changelog","previous_headings":"","what":"eatRep 0.13.5","title":"eatRep 0.13.5","text":"CRAN release: 2021-03-02 added vignette added balanced repeated replication example examples repMean() added internal check persons nested within groups","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"bug-fixes-0-13-5","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"eatRep 0.13.5","text":"fixed report cross differences levels grouping variable contained variable name fixed missing entries mode column output repMean() eatRep::repMean(...) now works well library(eatRep); repMean(...) added tests repGlm() function","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-01349000","dir":"Changelog","previous_headings":"","what":"eatRep 0.13.4.9000","title":"eatRep 0.13.4.9000","text":"Switch Github Action CI","code":""},{"path":"https://weirichs.github.io/eatRep/news/index.html","id":"eatrep-0134","dir":"Changelog","previous_headings":"","what":"eatRep 0.13.4","title":"eatRep 0.13.4","text":"CRAN release: 2021-01-08 Initial CRAN release","code":""}]
